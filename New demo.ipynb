{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9adcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "weave.use_frontend_devmode()\n",
    "weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66380db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.ecosystem import ecosystem\n",
    "# TODO: doesn't work and should be \"weave\"\n",
    "#ecosystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show file browsing to a csv\n",
    "# TODO: doesn't work\n",
    "weave.ops.local_path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27623c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table, plotting, etc\n",
    "\n",
    "# TODO:\n",
    "#   - better (bigger, more interesting) data\n",
    "#   - fix this API (local_path, readcsv)\n",
    "#   - Weave expression readcsv doesn't match code .readcsv() [can fix this with copy to code button]\n",
    "#   - it'd be really nice to have two options when copying to code \"copy expression, copy Panel\"\n",
    "#     - can show how copying the table has all the lambdas\n",
    "#     - and you can learn the API this way\n",
    "#     - every panel needs a to_code. Most of them should be standard!\n",
    "#   - first flip this to plot\n",
    "#   - then do \"open to side\" interaction to drilldown\n",
    "#   - then get back the code for that UI state\n",
    "weave.ops.local_path('weave/testdata/cereal.csv').readcsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c319d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate in home browser to packages, openai\n",
    "# TODO:\n",
    "#   - home browser\n",
    "#   - langchain is the namespace?\n",
    "#   - how do we get back to this op if its not imported\n",
    "#   - code generation needs to generate import statements!\n",
    "\n",
    "# example\n",
    "#  chat_openai(\"gpt-3.5-turbo\", 0.7).predict(\n",
    "#  \"You are the greatest art critic of all time. Describe a painting of Pablo Picasso's as accurately as you can such that some reading only your description would understand the character of his work.\")\n",
    "#  .replace(\"Picasso\", \"The artist\").stable_diffusion\n",
    "#\n",
    "# Note: I actually went through this myself!\n",
    "#   I fed it into stable_diffusion originally\n",
    "#   But it painted like an actual Picasso\n",
    "#   I realized his name was in the prompt\n",
    "#   So I did a replace op to get it out\n",
    "#   Then fed that into stable_diffusion\n",
    "#   Much better!\n",
    "# TODO: I'm getting some deserialize error here\n",
    "\n",
    "# For now do this:\n",
    "from weave.ecosystem import langchain\n",
    "langchain.chat_openai(model_name=\"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c66aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#   - do I explain weave.save here?\n",
    "#     - or just use wave.show (which should probably be just weave())\n",
    "#   - this errors when I run the models list by itself\n",
    "#   - output is a shitty String-Histogram, need to keep inputs alongside\n",
    "#     Do we use tags here our output dictionaries and make you do further access?\n",
    "# comparison\n",
    "#\n",
    "# want to do this\n",
    "#   (convert to bytes, feedback to model)\n",
    "#   get(\"local-artifact:///list:74ea71de019aba1db0df/obj\").predict(\"You are the greatest art critic of all time. Describe a painting of Pablo Picasso's as accurately as you can such that some reading only your description would understand the character of his work.\").replace(\"Picasso\", \"The artist\").stable_diffusion.image_bytes.map((row, index) => get(\"local-artifact:///list:74ea71de019aba1db0df/obj\")[0].predict(row))\n",
    "#   but I get an error:\n",
    "#       File \"/Users/shawn/code2/weave-internal/weave/language_features/tagging/process_opdef_resolve_fn.py\", line 130, in process_opdef_resolve_fn\n",
    "#    res = resolve_fn(*args, **kwargs)\n",
    "#  File \"/Users/shawn/code2/weave-internal/weave/ecosystem/langchain/lc.py\", line 471, in predict\n",
    "#    return self.predict(text)\n",
    "# Why did we not read this in?\n",
    "#AttributeError: 'OutputNode' object has no attribute 'predict'\n",
    "models = weave.save([\n",
    "    langchain.chat_openai(model_name=\"gpt-3.5-turbo\", temperature=0.7),\n",
    "    langchain.chat_anthropic('claude-v1', temperature=0.7)])\n",
    "models.predict('hello')\n",
    "#models.predict(\"You are the greatest art critic of all time. Describe a painting of Pablo Picasso's as accurately as you can such that some reading only your description would understand the character of his work.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ec5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now build up a bunch of prompts\n",
    "# Maybe we actually want to understand if it can read images from byte strings\n",
    "# we can build \"hone\" a tool (a dashboard), that helps you explore that\n",
    "# try various:\n",
    "#   prompts \n",
    "#   byte encodings\n",
    "#   etc\n",
    "models.predict(\"You are the greatest art critic of all time. Describe a painting of Pablo Picasso's as accurately as you can such that some reading only your description would understand the character of his work.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
