{"cells":[{"cell_type":"markdown","id":"298501c0","metadata":{"id":"298501c0"},"source":["<!-- docusaurus_head_meta::start\n","---\n","title: Introduction Notebook\n","---\n","docusaurus_head_meta::end -->\n","\n","<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n","<!--- @wandbcode{intro-colab} -->"]},{"cell_type":"markdown","id":"vocyElGYmk06","metadata":{"id":"vocyElGYmk06"},"source":["# Evaluating hallucination in RAG Pipelines with Weave Integration\n","\n","This notebook demonstrates how to evaluate hallucination of language models in answers coming from a Retrieval-Augmented Generation (RAG) response. We will integrate this with Weave for tracking function inputs and outputs, creating objects out of prompts, and running evaluations with different datasets.\n","\n","## Objectives:\n","\n","* Implement a RAG pipeline that includes  hallucination detection mechanism using an open source ML model trained specifically for hallucination detection.\n","* Integrate Weave to track all function calls, inputs, and outputs.\n","* Register three different evaluation datasets and showcase evaluation steps.\n","\n","## Stack Used:\n","\n","* OpenAI API for language models and embeddings.\n","* Weave by Weights & Biases for tracking and evaluation.\n","* open source hallucination_evaluation_model from hugging face\n","\n","Note:Ensure you have the necessary API keys set up in your environment.\n","\n"]},{"cell_type":"markdown","id":"56dc5c9d","metadata":{"id":"56dc5c9d"},"source":["## 🪄 Install `weave` library and login\n","\n","\n","Start by installing the library and logging in to your account.\n","\n","In this example, we're using openai so you should [add an openai API key](https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key).\n","\n"]},{"cell_type":"code","execution_count":null,"id":"WqDMY26fdOyN","metadata":{"id":"WqDMY26fdOyN"},"outputs":[],"source":["%%capture\n","!pip install weave \\\n","openai set-env-colab-kaggle-dotenv \\\n","requests \\\n","python-dotenv==1.0.1 \\\n","PyPDF2 \\\n","unstructured \\\n","pdfminer.six \\\n","transformers \\\n","nltk \\\n","torch \\\n","llama-index\n"]},{"cell_type":"code","execution_count":null,"id":"a0ec16b7","metadata":{},"outputs":[],"source":["from set_env import set_env\n","# Set your OpenAI API key\n","# Put your OPENAI_API_KEY in the secrets panel to the left 🗝️\n","_ = set_env(\"OPENAI_API_KEY\")\n","# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\" # alternatively, put your key here\n","PROJECT = \"Hallucination_Check\""]},{"cell_type":"code","execution_count":null,"id":"j9wRyq2QuT0G","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"id":"j9wRyq2QuT0G","outputId":"b0c701b7-713c-4317-ed30-31b8e97117a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Please login to Weights & Biases (https://wandb.ai/) to continue:\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"]},{"data":{"application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","WARNING:weave.trace.env:There are different credentials in the netrc file and the environment. Using the environment value.\n"]},{"name":"stdout","output_type":"stream","text":["Logged in as Weights & Biases user: mg01.\n","View Weave data at https://wandb.ai/wandb-smle/hallucination_check/weave\n"]},{"data":{"text/plain":["<weave.trace.weave_client.WeaveClient at 0x7c73b437c3d0>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import weave\n","weave.init(PROJECT)  # initialize tracking for a specific W&B project"]},{"cell_type":"markdown","id":"9nkl6QL9oOS0","metadata":{"id":"9nkl6QL9oOS0"},"source":["\n","## 📚 Import Necessary Libraries\n","\n","We'll import all the required libraries for our project:\n"]},{"cell_type":"code","execution_count":null,"id":"ohVAmScbp2Cx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ohVAmScbp2Cx","outputId":"d34fd883-bd98-484c-c046-eeaf8864ca28"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","import os\n","import requests\n","import torch\n","import weave\n","from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n","from llama_index.embeddings.openai import OpenAIEmbedding\n","from openai import OpenAI\n","from typing import List, Dict, Any\n","\n","nltk.download('punkt')\n"]},{"cell_type":"markdown","id":"hZsva0IfKV8k","metadata":{"id":"hZsva0IfKV8k"},"source":["Loading Hallucination detection model"]},{"cell_type":"code","execution_count":null,"id":"OAk4u8khKTDk","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"OAk4u8khKTDk","outputId":"0dff0eee-9815-461a-c63e-43c315d14357"},"outputs":[{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/vectara/hallucination_evaluation_model:\n","- configuration_hhem_v2.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","You are using a model of type HHEMv2Config to instantiate a model of type HHEMv2. This is not supported for all configurations of models and can yield errors.\n","A new version of the following files was downloaded from https://huggingface.co/vectara/hallucination_evaluation_model:\n","- modeling_hhem_v2.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]}],"source":["%%capture\n","# Load the model with custom code\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"vectara/hallucination_evaluation_model\", trust_remote_code=True\n",")\n","model.eval()  # Set the model to evaluation mode"]},{"cell_type":"markdown","id":"FgYcqJNCqEEX","metadata":{"id":"FgYcqJNCqEEX"},"source":["## 🔑 Initialize OpenAI Client and Embedding Model\n","\n","Create an OpenAI client instance for API calls and set up the embedding model.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"WMCBSnemqImN","metadata":{"id":"WMCBSnemqImN"},"outputs":[],"source":["# Initialize OpenAI client\n","client = OpenAI(\n","    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",")\n","\n","# Set up embedding model\n","embedding_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n"]},{"cell_type":"markdown","id":"vWwvfmZMqLb8","metadata":{"id":"vWwvfmZMqLb8"},"source":["## 📥 Download and Load Documents\n","\n","We'll download a PDF document from a URL and create an index using LlamaIndex. Please note taht this can be your own vector database with your data indexed for your RAG Chatbot.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"knrRJg2jqWQV","metadata":{"id":"knrRJg2jqWQV"},"outputs":[],"source":["# Download the PDF from a URL\n","pdf_url = \"https://arxiv.org/pdf/2408.13296v1.pdf\"  # Replace with your PDF URL\n","pdf_filename = \"document.pdf\"\n","\n","response = requests.get(pdf_url)\n","with open(pdf_filename, 'wb') as f:\n","    f.write(response.content)\n","\n","# Load the documents from the PDF\n","documents = SimpleDirectoryReader(input_dir='.', required_exts=['.pdf']).load_data()\n","\n","# Create the index from the documents\n","index = VectorStoreIndex.from_documents(documents, embed_model=embedding_model)\n"]},{"cell_type":"markdown","id":"QpX3QNwmqZ25","metadata":{"id":"QpX3QNwmqZ25"},"source":["## 🔎 Create Query Engine\n","\n","Set up the query engine with a limit on the number of retrieved documents.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"Lx1hwfJ8qXsf","metadata":{"id":"Lx1hwfJ8qXsf"},"outputs":[],"source":["# Create the query engine\n","query_engine = index.as_query_engine(similarity_top_k=3)\n"]},{"cell_type":"markdown","id":"DgbL1Ex7qfAS","metadata":{"id":"DgbL1Ex7qfAS"},"source":["## 🛠️ Define Weave-Tracked Functions\n","\n","We'll define our functions for the pipeline and use `@weave.op()` to decorate them, enabling Weave to track their inputs and outputs.\n","\n","### 1. Retrieve Context\n","\n","This function retrieves relevant context for the question using the LlamaIndex query engine.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"vIp1U2-atlXT","metadata":{"id":"vIp1U2-atlXT"},"outputs":[],"source":["@weave.op()\n","def retrieve_context(question: str) -> str:\n","    '''Retrieves relevant context for the question using LlamaIndex query engine.'''\n","    response = query_engine.query(question)\n","    context = str(response)\n","    return context\n"]},{"cell_type":"markdown","id":"hzKPXo6atorE","metadata":{"id":"hzKPXo6atorE"},"source":["### 2. Generate Answer\n","\n","This function generates an answer to the question based on the provided context using OpenAI's GPT model.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"vgZ0-KlPtb4t","metadata":{"id":"vgZ0-KlPtb4t"},"outputs":[],"source":["@weave.op()\n","def generate_answer(question: str, context: str, model_name: str) -> str:\n","    '''Generates an answer to the question based on the provided context using OpenAI's GPT model.'''\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context.\"},\n","        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion:\\n{question}\"}\n","    ]\n","    response = client.chat.completions.create(\n","        model=model_name,\n","        messages=messages,\n","        max_tokens=200,\n","        temperature=0.7,\n","        n=1,\n","    )\n","    answer = response.choices[0].message.content.strip()\n","    return answer\n"]},{"cell_type":"markdown","id":"IhU9mdo_Tr6X","metadata":{"id":"IhU9mdo_Tr6X"},"source":["### 3. Break Down Answer into Statements\n","\n","This function breaks down the answer into simpler statements without pronouns.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"xwYGAbLKTt_-","metadata":{"id":"xwYGAbLKTt_-"},"outputs":[],"source":["weave.op()\n","def break_down_answer_into_statements(answer: str, model_name: str) -> List[str]:\n","    '''Breaks down the answer into simpler statements without pronouns.'''\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"You simplify answers into fully understandable statements without pronouns.\"},\n","        {\"role\": \"user\", \"content\": f\"Break down the following answer into a list of simpler statements, ensuring each statement is fully understandable and contains no pronouns.\\n\\nAnswer:\\n{answer}\\n\\nStatements:\"}\n","    ]\n","    response = client.chat.completions.create(\n","        model=model_name,\n","        messages=messages,\n","        max_tokens=300,\n","        temperature=0.5,\n","        n=1,\n","    )\n","    statements_text = response.choices[0].message.content.strip()\n","    # Parse statements as a list\n","    statements = [s.strip().strip('.').strip() for s in statements_text.split('\\n') if s.strip()]\n","    # Remove any numbering or bullets\n","    statements = [s.lstrip('0123456789.- ') for s in statements]\n","    return statements\n"]},{"cell_type":"markdown","id":"t5nkSEnNtskG","metadata":{"id":"t5nkSEnNtskG"},"source":["### 4. Detect statement Hallucination\n","\n"]},{"cell_type":"code","execution_count":null,"id":"GyYkI1fU2kLn","metadata":{"id":"GyYkI1fU2kLn"},"outputs":[],"source":["from typing import Dict, Any\n","\n","@weave.op()\n","def check_statement_hallucination(context: str, statement: str) -> Dict[str, Any]:\n","    '''Detects hallucination in the answer using the provided context and model answer.'''\n","    pairs = [(context, statement)]\n","    with torch.no_grad():\n","        outputs = model.predict(pairs)\n","        # The outputs are probabilities, we round them to get binary predictions\n","        preds = torch.round(outputs)\n","\n","\n","    for pair, pred in zip(pairs, preds):\n","        result = {\n","            'statement': pair[1],\n","            'prediction': 1 if pred.item() == 1.0 else 0\n","        }\n","\n","\n","    return result\n"]},{"cell_type":"markdown","id":"47-SMSxKyr_N","metadata":{"id":"47-SMSxKyr_N"},"source":["## 📊 Register Evaluation Dataset\n","\n","We'll create and register a single evaluation dataset in Weave. This dataset will be used to evaluate the faithfulness of the generated answers.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"3ZjWDzF6yu_J","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZjWDzF6yu_J","outputId":"f3e99f35-7902-4540-e3dd-bbc84ba0c27c"},"outputs":[{"name":"stdout","output_type":"stream","text":["📦 Published to https://wandb.ai/wandb-smle/hallucination_check/weave/objects/Hallucination_Evaluation_Dataset/versions/XHYkK66pfjsKbbbaSfKL4oQPkxGRTfqJN1CCOetxiV8\n"]},{"data":{"text/plain":["ObjectRef(entity='wandb-smle', project='hallucination_check', name='Hallucination_Evaluation_Dataset', digest='XHYkK66pfjsKbbbaSfKL4oQPkxGRTfqJN1CCOetxiV8', extra=())"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Define the dataset\n","dataset = weave.Dataset(\n","    name=\"Hallucination_Evaluation_Dataset\",\n","    rows=[\n","        {\"question\": \"What are the limitations of the Transformers library and Trainer API?\"},\n","        {\"question\": \"How Azure Open AI fine-tuning is different from Open AI fine tuning\"},\n","        {\"question\": \"Why fine-tuning GPT-4 is more challenging than GPT-3.5\"},\n","        {\"question\": \"Explain why fine-tuning is cheaper compared to few shot learning?\"},\n","        {\"question\": \"How we can fine tune the new GPT o1 preview model? ( not that this is a different model compared to GPT-01)\"},\n","    ],\n",")\n","\n","# Publish dataset to Weave\n","weave.publish(dataset)\n"]},{"cell_type":"markdown","id":"PuyLbmf3yydn","metadata":{"id":"PuyLbmf3yydn"},"source":["## 🧪 Define End-to-End Pipeline as a Weave Model\n","\n","We'll define an end-to-end pipeline as a Weave Model. This allows us to use it for evaluation later and makes the entire process reproducible and traceable.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"-FzT7b5w3dmq","metadata":{"id":"-FzT7b5w3dmq"},"outputs":[],"source":["class HallucinationEvaluator(weave.Model):\n","    model_name: str = \"gpt-3.5-turbo\"\n","\n","    @weave.op()\n","    def predict(self, question: str) -> Dict[str, Any]:\n","        '''Generates an answer to the question based on retrieved context.Returns a dict with 'answer', 'context', and 'model_name'.'''\n","        # Retrieve context\n","        context = retrieve_context(question)\n","        # Generate answer\n","        answer = generate_answer(question, context, self.model_name)\n","        return {'answer': answer, 'context': context, 'model_name': self.model_name}\n"]},{"cell_type":"markdown","id":"AQXTvtiXy24n","metadata":{"id":"AQXTvtiXy24n"},"source":["## 📝 Define Scorer Function\n","\n","We'll define a scorer function that computes the faithfulness score of the model's answer. This function will be used by Weave's `Evaluation` class.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"gch0yxmVy1oL","metadata":{"id":"gch0yxmVy1oL"},"outputs":[],"source":["@weave.op()\n","def hallucination_scorer(model_output: Dict[str, Any]) -> Dict[str, Any]:\n","    '''Scorer function that computes the factual score of the model's answer for evaluating hallucination.'''\n","    answer = model_output['answer']\n","    context = model_output['context']\n","    model_name = model_output['model_name']\n","    statements = break_down_answer_into_statements(answer, model_name)\n","    total_statements = len(statements)\n","    factual_statements = 0\n","    statement_results = []\n","    for statement in statements:\n","        result = check_statement_hallucination(context, statement)  # Fixed: use statement instead of answer\n","        factual_statements += result['prediction']\n","        statement_results.append({\n","            'prediction': result['prediction'],\n","            'statement': result['statement']\n","        })\n","    # Calculate faithfulness score\n","    if total_statements > 0:\n","        factual_score = factual_statements / total_statements\n","    else:\n","        factual_score = 0\n","    # Return results\n","    return {\n","        'factual_score': factual_score,\n","        'statement_results': statement_results,\n","    }"]},{"cell_type":"markdown","id":"RZdp6ed-y60P","metadata":{"id":"RZdp6ed-y60P"},"source":["## 🚀 Run Evaluation Using Weave's `Evaluation` Class\n","\n","We'll use Weave's `Evaluation` class to run the evaluation, ensuring that the results are stored in the **'eval'** section of Weave.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"A63gByJ7y8l4","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"A63gByJ7y8l4","outputId":"ba0e8a53-8059-41a4-8f2b-a247807c2eb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:weave.trace.env:There are different credentials in the netrc file and the environment. Using the environment value.\n"]},{"name":"stdout","output_type":"stream","text":["Logged in as Weights & Biases user: mg01.\n","View Weave data at https://wandb.ai/wandb-smle/hallucination_check/weave\n","Running evaluation with model: gpt-3.5-turbo\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n","<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'hallucination_scorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'factual_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.912652826309204</span><span style=\"font-weight: bold\">}}</span>\n","</pre>\n"],"text/plain":["Evaluation summary\n","\u001b[1m{\u001b[0m\u001b[32m'hallucination_scorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'factual_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m8.912652826309204\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["🍩 https://wandb.ai/wandb-smle/hallucination_check/r/call/01927e63-0dda-7a82-9cb6-e45d1603296f\n","Completed evaluation with model: gpt-3.5-turbo\n","\n","Running evaluation with model: gpt-4o\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n","</pre>\n"],"text/plain":["Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n","<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'hallucination_scorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'factual_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.310395002365112</span><span style=\"font-weight: bold\">}}</span>\n","</pre>\n"],"text/plain":["Evaluation summary\n","\u001b[1m{\u001b[0m\u001b[32m'hallucination_scorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'factual_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.8\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m5.310395002365112\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["🍩 https://wandb.ai/wandb-smle/hallucination_check/r/call/01927e63-b140-73d3-bc4f-19935b055d4f\n","Completed evaluation with model: gpt-4o\n","\n"]}],"source":["import asyncio\n","import nest_asyncio\n","from weave import Evaluation\n","# Initialize Weave\n","weave.init(PROJECT)\n","\n","# Apply nest_asyncio to allow nested event loops in Colab\n","nest_asyncio.apply()\n","\n","# Run the evaluation for both models\n","\n","# Define the models to evaluate\n","model_names = [\"gpt-3.5-turbo\", \"gpt-4o\"]\n","\n","for model_name in model_names:\n","    print(f\"Running evaluation with model: {model_name}\")\n","    # Instantiate the evaluator model with the specified model name\n","    evaluator_model = HallucinationEvaluator(model_name=model_name)\n","\n","    # Define the evaluation\n","    evaluation = Evaluation(\n","        dataset=dataset,  # the dataset we have defined earlier\n","        scorers=[hallucination_scorer],  # the scorer function\n","    )\n","\n","    # Run the evaluation\n","    summary = asyncio.run(evaluation.evaluate(evaluator_model))\n","\n","    print(f\"Completed evaluation with model: {model_name}\\n\")"]},{"cell_type":"markdown","id":"D76yqHtB1Is3","metadata":{"id":"D76yqHtB1Is3"},"source":["## 📌 Conclusion\n","\n","**Evaluation of Faithfulness**:\n","\n","In this notebook, we focused on evaluating the **faithfulness** of answers generated by our\n","Retrieval-Augmented Generation (RAG) system. By breaking down the answers into simpler\n","statements and checking each one against the retrieved context, we quantified how much we can\n","**trust** the responses provided by the system.\n","\n"," **How Weave Helps**:\n","\n"," Weave played a crucial role in this process by:\n","\n"," - **Tracking**: Weave's `@weave.op()` decorators allowed us to track the inputs and outputs of our\n","   functions seamlessly. This provided transparency into each step of our pipeline.\n"," - **Evaluation**: Using Weave's `Evaluation` class, we conducted structured evaluations and stored\n","   the results in the **'eval'** section. This made it easy to analyze and compare results.\n"," - **Reproducibility**: By defining our prompts and models as Weave Objects and Models, we ensured\n","   that our pipeline is reproducible and easily shareable.\n","\n"," **Benefits of Weave Integration**:\n","\n"," - **Enhanced Trust**: By integrating faithfulness evaluation, we added an extra layer of **trust** to\n","   our system. Users can be more confident in the accuracy of the responses.\n"," - **Debugging and Improvement**: Weave's tracking capabilities make it easier to identify areas\n","  where the model may not be performing as expected, facilitating targeted improvements.\n","- **Comprehensive Insights**: The ability to store and analyze evaluation results within Weave\n","   provides comprehensive insights into model performance over time.\n","\n"," ---\n","\n"," ## 🔚 Final Thoughts\n","\n"," By integrating **Weave** into our code, we've enhanced the transparency, reliability, and\n"," **trustworthiness** of our RAG system. We can:\n","\n"," - Track function inputs and outputs.\n"," - Reuse prompt templates as Weave Objects.\n"," - Perform comprehensive evaluations focused on faithfulness.\n"," - Define an end-to-end pipeline as a Weave Model for easier evaluation.\n"," - Store evaluation results in the **'eval'** section of Weave for better analysis.\n","\n"," This approach not only provides valuable insights into the trustworthiness of the generated\n"," answers but also contributes to building systems that users can rely on with confidence.\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}
