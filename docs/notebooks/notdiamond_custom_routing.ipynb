{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Routing for LLM Prompts with Not Diamond\n",
    "\n",
    "This notebook demonstrates how to use Weave with [Not Diamond's custom routing](https://docs.notdiamond.ai/docs/router-training-quickstart) to route LLM prompts to the most appropriate model based on evaluation results.\n",
    "\n",
    "## Routing prompts\n",
    "\n",
    "When building complex LLM workflows users may need to prompt different models according to accuracy, cost, or call latency. \n",
    "Users can use [Not Diamond](https://www.notdiamond.ai/) to route prompts in these workflows to the right model for their needs, helping maximize accuracy while saving on model costs.\n",
    "\n",
    "For any given distribution of data, rarely will one single model outperform every other model on every single query. By combining together multiple models into a \"meta-model\" that learns when to call each LLM, you can beat every individual model's performance and even drive down costs and latency in the process.\n",
    "\n",
    "## Custom routing\n",
    "\n",
    "You need three things to train a custom router for your prompts:\n",
    "\n",
    "1. A set of LLM prompts: Prompts must be strings and should be representative of the prompts used in our application.\n",
    "1. LLM responses: The responses from candidate LLMs for each input. Candidate LLMs can include both our supported LLMs and your own custom models.\n",
    "1. Evaluation scores for responses to the inputs from candidate LLMs: Scores are numbers, and can be any metric that fit your needs.\n",
    "\n",
    "By submitting these to the Not Diamond API you can then train a custom router tuned to each of your workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training data\n",
    "\n",
    "In practice, you will use your own Evaluations to train a custom router. For this example notebook, however, you will use LLM responses \n",
    "for [the HumanEval dataset](https://github.com/openai/human-eval) to train a custom router for coding tasks.\n",
    "\n",
    "We start by downloading the dataset we have prepared for this example, then parsing LLM responses into EvaluationResults for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  595k  100  595k    0     0   233k      0  0:00:02  0:00:02 --:--:--  412k\n"
     ]
    }
   ],
   "source": [
    "!curl -L \"https://drive.google.com/uc?export=download&id=1q1zNZHioy9B7M-WRjsJPkfvFosfaHX38\" -o humaneval.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 164 rows for anthropic/claude-3-5-sonnet-20240620.\n",
      "Found 164 rows for openai/gpt-4o-2024-05-13.\n",
      "Found 164 rows for google/gemini-1.5-pro-latest.\n",
      "Found 164 rows for openai/gpt-4-turbo-2024-04-09.\n",
      "Found 164 rows for anthropic/claude-3-opus-20240229.\n"
     ]
    }
   ],
   "source": [
    "from weave.integrations.notdiamond.custom_router_test import get_model_evals\n",
    "\n",
    "model_evals = get_model_evals('./humaneval.csv')\n",
    "for model, evaluation_results in model_evals.items():\n",
    "    print(f\"Found {len(evaluation_results.rows)} rows for {model}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a custom router\n",
    "\n",
    "Now that you have EvaluationResults, you can train a custom router. Make sure you have [created an account](https://app.notdiamond.ai/keys) and \n",
    "[generated an API key](https://app.notdiamond.ai/keys), then insert your API key below.\n",
    "\n",
    "![Create an API key](../docs/guides/integrations/imgs/notdiamond/api-keys.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from weave.integrations.notdiamond.custom_router import train_evaluations\n",
    "\n",
    "api_key = os.getenv(\"NOTDIAMOND_API_KEY\", \"<YOUR_API_KEY>\")\n",
    "\n",
    "preference_id = train_evaluations(\n",
    "    model_evals=model_evals,\n",
    "    prompt_column=\"prompt\",\n",
    "    response_column=\"actual\",\n",
    "    language=\"en\",\n",
    "    maximize=True,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then follow the training process for your custom router via the Not Diamond app.\n",
    "\n",
    "![Check on router training progress](../docs/guides/integrations/imgs/notdiamond/router-preferences.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your custom router has finished training, you can use it to route your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游꼴 https://wandb.ai/notdiamond/dev_testing/r/call/01924a65-7f09-7ba3-8eaf-c8248e2be51e\n",
      "游꼴 https://wandb.ai/notdiamond/dev_testing/r/call/01924a65-7f14-7073-b4bf-dfc7b031fe4c\n",
      "游꼴 https://wandb.ai/notdiamond/dev_testing/r/call/01924a65-7f15-7881-b607-67c0de9928d5\n",
      "游꼴 https://wandb.ai/notdiamond/dev_testing/r/call/01924a65-7f16-71a0-a1d8-456ed6c83544\n",
      "游꼴 https://wandb.ai/notdiamond/dev_testing/r/call/01924a65-7f17-75f2-9316-d5e1ae8c5538\n",
      "游꼴 https://wandb.ai/notdiamond/dev_testing/r/call/01924a65-7f1f-7501-ae43-51dc16ed69b0\n",
      "Session ID: 71ac45e8-b9c2-44ee-a359-66eb07bfa8ec\n",
      "Target Model: anthropic/claude-3-opus-20240229\n"
     ]
    }
   ],
   "source": [
    "from notdiamond import NotDiamond\n",
    "import weave\n",
    "\n",
    "weave.init(\"dev_testing\")\n",
    "\n",
    "llm_configs = [\n",
    "    \"anthropic/claude-3-5-sonnet-20240620\",\n",
    "    \"openai/gpt-4o-2024-05-13\",\n",
    "    \"google/gemini-1.5-pro-latest\",\n",
    "    \"openai/gpt-4-turbo-2024-04-09\",\n",
    "    \"anthropic/claude-3-opus-20240229\",\n",
    "]\n",
    "client = NotDiamond(api_key=api_key, llm_configs=llm_configs)\n",
    "\n",
    "new_prompt = \"\"\"\n",
    "You are a helpful coding assistant. Using the provided function signature, write the implementation for the function\n",
    "in Python. Write only the function. Do not include any other text.\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "    \"\"\"\"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
    "    given threshold.\n",
    "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
    "    False\n",
    "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
    "    True\n",
    "    \"\"\"\"\"\"\n",
    "\"\"\"\n",
    "session_id, routing_target_model = client.model_select(\n",
    "    messages=[{\"role\": \"user\", \"content\": new_prompt}],\n",
    "    preference_id=preference_id,\n",
    ")\n",
    "\n",
    "print(f\"Session ID: {session_id}\")\n",
    "print(f\"Target Model: {routing_target_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example also used Not Diamond's compatibility with Weave auto-tracing. You can see the results in the Weave UI.\n",
    "\n",
    "![Weave UI for custom routing](../docs/guides/integrations/imgs/notdiamond/weave-trace.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weave-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
