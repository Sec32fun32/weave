{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679b34ca-1d37-4991-8552-542bce21063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354ebb13-cff0-4aba-8383-462615a633ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphClientSql()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weave.init_sql_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c66549-9981-41b1-9630-d54f92008028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.weaveflow import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32cf318b-8337-4b08-bf10-999b6e9f2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset([{'a': 5, 'b': 6}, {'a': 7, 'b': 10}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ecf7b30-8d9f-4bec-99a5-ba8ad622d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published Dataset to [no url for obj]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© View call: <UI URL NOT IMPLEMENTED>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'color_score': {'correct': {'true_count': 3, 'true_fraction': 1.0}},\n",
       " 'fruit_name_score': {'correct': {'true_count': 2,\n",
       "   'true_fraction': 0.6666666666666666}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weave\n",
    "import asyncio\n",
    "from weave.weaveflow import Model, Evaluation, Dataset\n",
    "import json\n",
    "\n",
    "# We create a model class with one predict function. \n",
    "# All inputs, predictions and parameters are automatically captured for easy inspection.\n",
    "@weave.type()\n",
    "class ExtractFruitsModel(Model):\n",
    "    system_message: str\n",
    "    model_name: str = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "    @weave.op()\n",
    "    async def predict(self, sentence: str) -> str:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": self.system_message\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": sentence\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            response_format={ \"type\": \"json_object\" }\n",
    "        )\n",
    "        extracted = response.choices[0].message.content\n",
    "        return json.loads(extracted)\n",
    "\n",
    "# We call init to begin capturing data in the project, intro-example.\n",
    "weave.init_sql_client()\n",
    "\n",
    "# We create our model with our system prompt.\n",
    "model = ExtractFruitsModel(\"You will be provided with unstructured data, and your task is to parse it one JSON dictionary with fruit, color and flavor as keys.\")\n",
    "sentences = [\"There are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy.\", \n",
    "\"Pounits are a bright green color and are more savory than sweet.\", \n",
    "\"Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"]\n",
    "labels = [\n",
    "    {'fruit': 'neoskizzles', 'color': 'purple', 'flavor': 'candy'},\n",
    "    {'fruit': 'pounits', 'color': 'bright green', 'flavor': 'savory'},\n",
    "    {'fruit': 'glowls', 'color': 'pale orange', 'flavor': 'sour and bitter'}\n",
    "]\n",
    "# Here, we track a Dataset in weave. This makes it easy to \n",
    "# automatically score a given model and compare outputs from different configurations.\n",
    "dataset = Dataset([\n",
    "    {'id': '0', 'sentence': sentences[0], 'extracted': labels[0]},\n",
    "    {'id': '1', 'sentence': sentences[1], 'extracted': labels[1]},\n",
    "    {'id': '2', 'sentence': sentences[2], 'extracted': labels[2]}\n",
    "])\n",
    "dataset_ref = weave.publish(dataset, 'example_labels')\n",
    "# If you have already published the Dataset, you can run:\n",
    "# dataset = weave.ref('example_labels').get()\n",
    "\n",
    "# We define two scoring functions to compare our model predictions with a ground truth label.\n",
    "@weave.op()\n",
    "def color_score(example: dict, prediction: dict) -> dict:\n",
    "    # example is a row from the Dataset, prediction is the output of predict function\n",
    "    return {'correct': example['extracted']['color'] == prediction['color']}\n",
    "\n",
    "@weave.op()\n",
    "def fruit_name_score(example: dict, prediction: dict) -> dict:\n",
    "    return {'correct': example['extracted']['fruit'] == prediction['fruit']}\n",
    "\n",
    "@weave.op()\n",
    "def example_to_model_input(example: dict) -> str:\n",
    "    # example is a row from the Dataset, the output of this function should be the input to model.predict.\n",
    "    return example[\"sentence\"]\n",
    "\n",
    "# Finally, we run an evaluation of this model. \n",
    "# This will generate a prediction for each input example, and then score it with each scoring function.\n",
    "evaluation = Evaluation(\n",
    "    dataset, scores=[color_score, fruit_name_score], example_to_model_input=example_to_model_input\n",
    ")\n",
    "#print(asyncio.run(evaluation.evaluate(model)))\n",
    "# if you're in a Jupyter Notebook, run:\n",
    "await evaluation.evaluate(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
