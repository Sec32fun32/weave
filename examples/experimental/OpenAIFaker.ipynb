{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb58d3-605b-4c32-9cb9-f7c5250a7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def make_example(start_time_s=None, end_time_s=None):\n",
    "    latency = 0.5\n",
    "    if end_time_s is None:\n",
    "        end_time_s = datetime.now().timestamp()\n",
    "    if start_time_s is None:\n",
    "        start_time_s = end_time_s - latency\n",
    "    return {\n",
    "        \"timestamp\": datetime.datetime.fromtimestamp(end_time_s),\n",
    "        \"parent_id\": None, \n",
    "        \"trace_id\": \"b4135bb7-37f2-4079-b098-b64d772347a7\", \n",
    "        \"span_id\": \"9346c105-23ea-4986-9ca2-0a632f58db22\", \n",
    "        \"name\": \"openai.api_resources.chat_completion.type.create\", \n",
    "        \"status_code\": \"SUCCESS\", \n",
    "        \"start_time_s\": start_time_s, \n",
    "        \"end_time_s\": end_time_s, \n",
    "        \"inputs\": {\n",
    "            \"model\": \"gpt-3.5-turbo\", \n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"hello world!\"}\n",
    "            ]\n",
    "        }, \n",
    "        \"output\": {\n",
    "            \"id\": \"chatcmpl-7oNPesyWfokf1Pi0DQMG2CAMqb6g1\", \n",
    "            \"object\": \"chat.completion\", \n",
    "            \"created\": int(end_time_s), \n",
    "            \"model\": \"gpt-3.5-turbo-0613\", \n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"index\": 0, \n",
    "                    \"message\": {\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": \"Hello! How can I assist you today?\"\n",
    "                    }, \n",
    "                    \"finish_reason\": \"stop\"\n",
    "                }\n",
    "            ]\n",
    "        }, \n",
    "        \"exception\": None, \n",
    "        \"attributes\": {\n",
    "            \"api_key\": \"sk-...xAF0\"\n",
    "        }, \n",
    "        \"summary\": {\n",
    "            \"prompt_tokens\": 10, \n",
    "            \"completion_tokens\": 9, \n",
    "            \"total_tokens\": 19, \n",
    "            \"latency_s\": latency\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cff860-e17b-4361-88dd-5d04a72e49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weave.monitoring import StreamTable\n",
    "\n",
    "NUM_ROWS = 1_000\n",
    "\n",
    "st = StreamTable(f\"timssweeney/oai_scale_test/stream_{NUM_ROWS}_init_test_1\")\n",
    "\n",
    "min_timestamp = datetime.datetime.now().timestamp() - 24 * 60 * 60\n",
    "\n",
    "for i in range(NUM_ROWS):\n",
    "    gap = (datetime.datetime.now().timestamp() - min_timestamp) * ((NUM_ROWS - i - 1) / NUM_ROWS)\n",
    "    st.log(make_example(end_time_s = datetime.datetime.now().timestamp() - gap))\n",
    "    if i % (NUM_ROWS // 10) == 0:\n",
    "        print(10 * i / NUM_ROWS, '%')\n",
    "\n",
    "st.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4074392-bdd9-4161-9dc2-f6e81a196ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
