{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wandb/weave/blob/anish/add-spacerag-example/examples/cookbooks/rag/spacerag/part2.ipynb)\n",
    "<!--- @wandbcode{weave-spacerag-cookbook} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_COLAB = False\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n",
    "    os.environ[\"TOGETHER_API_KEY\"] = userdata.get(\"TOGETHER_API_KEY\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'weave_cookbooks' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "repo_url = \"https://github.com/wandb/weave.git\"\n",
    "target_folder = \"weave_cookbooks\"\n",
    "subdirectory = \"examples/cookbooks\"\n",
    "branch = \"anish/add-spacerag-example\"\n",
    "\n",
    "if not os.path.exists(target_folder) and IN_COLAB:\n",
    "    print(f\"Cloning repository: {repo_url}\")\n",
    "\n",
    "    # Clone the entire repository to a temporary folder\n",
    "    temp_folder = \"temp_weave_repo\"\n",
    "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", \"--branch\", branch, repo_url, temp_folder], check=True)\n",
    "\n",
    "    # Move the desired subdirectory to the target folder\n",
    "    shutil.move(os.path.join(temp_folder, subdirectory), target_folder)\n",
    "\n",
    "    # Remove the temporary folder\n",
    "    shutil.rmtree(temp_folder)\n",
    "\n",
    "    print(f\"Successfully cloned {subdirectory} from branch '{branch}' to {target_folder}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Folder '{target_folder}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(target_folder) and IN_COLAB:\n",
    "    %cd weave_cookbooks/summarization\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "from weave import Evaluation\n",
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from together import Together\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: a-sh0ts.\n",
      "View Weave data at https://wandb.ai/a-sh0ts/space_rag_example/weave\n"
     ]
    }
   ],
   "source": [
    "weave.init('space_rag_example')\n",
    "\n",
    "# SERVE MODEL FROM TOGETHER ENDPOINT\n",
    "client = Together(api_key=os.environ.get(\"TOGETHER_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK DATA FROM EXTERNAL KNOWLEDGEBASE\n",
    "@weave.op\n",
    "def get_chunked_data(file):\n",
    "    # get data - file\n",
    "    with open(file, 'r') as file:\n",
    "        # Read the contents of the file into a variable\n",
    "        text = file.read()\n",
    "\n",
    "    # split doc into chunks\n",
    "    chunk_size = 2048\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# EMBED DATA\n",
    "@weave.op\n",
    "def get_text_embedding(input):\n",
    "    api_key_openai = os.environ[\"OPENAI_API_KEY\"]\n",
    "    client = OpenAI(api_key=api_key_openai)\n",
    "    \n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=input\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# MAKE VECTORDB\n",
    "@weave.op\n",
    "def make_vector_db(file):\n",
    "    # get chunked data from function get_chunked_data()\n",
    "    chunks = get_chunked_data(file)\n",
    "    # embed data\n",
    "    text_embeddings = np.array([get_text_embedding(chunk) for chunk in chunks])\n",
    "    # embed data into vectordb\n",
    "    d = text_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(text_embeddings)\n",
    "    return index, chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/a-sh0ts/space_rag_example/r/call/15af1517-98c4-4fd3-9fb5-655896bc6fb7\n"
     ]
    }
   ],
   "source": [
    "file = './data/space.txt'\n",
    "index, chunks = make_vector_db(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER QUESTION\n",
    "@weave.op\n",
    "def predict(model, prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "        temperature=0.5,\n",
    "        top_p=1,\n",
    "        max_tokens=1024,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    answer = []\n",
    "    for chunk in completion:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            answer.append(chunk.choices[0].delta.content)\n",
    "    \n",
    "    result = ''.join(answer)\n",
    "    print(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRIEVE CHUNKS SIMILAR TO THE QUESTION\n",
    "@weave.op\n",
    "def retrieve_context(question: str) -> list:\n",
    "    question_embeddings = np.array([get_text_embedding(question)])\n",
    "    # Retrieve similar chunks from the vectorDB\n",
    "    D, I = index.search(question_embeddings, k=2) \n",
    "    retrieved_chunk = [chunks[i] for i in I.tolist()[0]]\n",
    "    return retrieved_chunk\n",
    "    \n",
    "class SpaceRAGModel(weave.Model):\n",
    "    model: str\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, question: str):\n",
    "        retrieved_chunk = retrieve_context(question)\n",
    "        print(\"Question: \"+question)\n",
    "\n",
    "        # Combine context and question in a prompt\n",
    "        prompt = f\"\"\"\n",
    "        Use this context to answer the question, don't use any prior knowledge.\n",
    "        Be concise in your answers.\n",
    "        ---------------------\n",
    "        {retrieved_chunk}\n",
    "        ---------------------\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        answer = predict(self.model, prompt)\n",
    "        print(\"___________________________\")\n",
    "        return {'answer': answer, 'retrieved_chunk': retrieved_chunk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_dict(input_string):\n",
    "    # Use regular expressions to find all JSON-like objects in the string\n",
    "    json_objects = re.findall(r'\\{.*?\\}', input_string)\n",
    "\n",
    "    # Initialize an empty dictionary to store the combined results\n",
    "    combined_dict = {}\n",
    "\n",
    "    for obj in json_objects:\n",
    "        try:\n",
    "            # Parse each JSON object\n",
    "            parsed_dict = json.loads(obj)\n",
    "            # Update the combined dictionary with the parsed data\n",
    "            combined_dict.update(parsed_dict)\n",
    "        except (ValueError, json.JSONDecodeError) as e:\n",
    "            print(f\"Error processing part: {obj}\\nError: {e}\")\n",
    "\n",
    "    return combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref = weave.ref(\"weave:///lavanyashukla/spacedata/object/space_dataset_llm_comprehensive:VBd5Ys7b3hGFmJJqdGTATVQYgKKrg70EiNV5FdpwFxs\").get()\n",
    "small_questions = dataset_ref.rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_in_dict(result):\n",
    "    for key in result:\n",
    "        if isinstance(result[key], float) and np.isnan(result[key]):\n",
    "            result[key] = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with an LLM\n",
    "@weave.op\n",
    "def llm_judge_scorer(ground_truth: str, model_output: dict) -> dict:\n",
    "    scorer_llm = \"meta-llama/Meta-Llama-3-70B-Instruct-Turbo\"\n",
    "    answer = model_output['answer']\n",
    "    retrieved_chunk = model_output['retrieved_chunk']\n",
    "\n",
    "    eval_rubrics = [\n",
    "    {\n",
    "        \"metric\": \"concise\",\n",
    "        \"rubrics\": \"\"\"\n",
    "        Score 1: The answer is rambling and difficult to understand.\n",
    "        Score 2: The answer is somewhat readable, engaging, or long winded.\n",
    "        Score 3: The answer is mostly easy to understand, and is somewhat consice.\n",
    "        Score 4: The answer is completely concise, readable and engaging.\n",
    "        \"\"\",\n",
    "    },\n",
    "    # {\n",
    "    #     \"metric\": \"relevant\",\n",
    "    #     \"rubrics\": \"\"\"\n",
    "    #     Score 1: The answer is not relevant to the original text. \n",
    "    #     Score 2: The answer is somewhat relevant to the original text, but has significant flaws.\n",
    "    #     Score 3: The answer is mostly relevant to the original text, and effectively conveys its main ideas and arguments.\n",
    "    #     Score 4: The answer is completely relevant to the original text, and provides additional value or insight.\n",
    "    #     \"\"\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"metric\": \"accurate\",\n",
    "    #     \"rubrics\": \"\"\"\n",
    "    #     Compare the factual content of the model's answer with the correct answer. Ignore any differences in style, grammar, or punctuation.\n",
    "    #     Score 1: There is a disagreement between the model's answer and the correct answer.\n",
    "    #     Score 2: The model's answer is a subset of the correct answer and is fully consistent with it.\n",
    "    #     Score 3: The answers differ, but these differences don't matter from the perspective of factuality.\n",
    "    #     Score 4: The model's answer contains all the same details as the correct answer.\n",
    "    #     \"\"\",\n",
    "    # },\n",
    "]\n",
    "\n",
    "    scoring_prompt = \"\"\"\n",
    "    You have the correct answer, original text and the model's answer below.\n",
    "    Based on the specified evaluation metric and rubric, assign an integer score between 1 and 4 to the summary. \n",
    "    Then, return a JSON object with the metric name as the key and the evaluation score as the value. Don't output anything else.\n",
    "\n",
    "    # Evaluation metric:\n",
    "    {metric}\n",
    "\n",
    "    # Evaluation rubrics:\n",
    "    {rubrics}\n",
    "\n",
    "    # Correct Answer\n",
    "    {ground_truth}\n",
    "    \n",
    "    # Original Text\n",
    "    {retrieved_chunk}\n",
    "\n",
    "    # Model Answer\n",
    "    {model_answer}\n",
    "\n",
    "    \"\"\"\n",
    "    evals = \"\"\n",
    "    for i in eval_rubrics:\n",
    "        eval_output = predict(scorer_llm,\n",
    "            scoring_prompt.format(\n",
    "                ground_truth=ground_truth, retrieved_chunk=retrieved_chunk, model_answer=answer,\n",
    "                metric=i[\"metric\"], rubrics=i[\"rubrics\"]\n",
    "            ))+\" \"\n",
    "        evals+=eval_output\n",
    "    # evals_json = format_string_to_json(evals)\n",
    "    evals_dict = string_to_dict(evals)\n",
    "    # print(\"___________________________\")\n",
    "    # print(evals_dict)\n",
    "    # print(\"___________________________\")\n",
    "    return evals_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ragas_score(question, ground_truth, model_output):\n",
    "    from datasets import Dataset\n",
    "    from ragas import evaluate\n",
    "    from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision\n",
    "\n",
    "    metric_modules = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        answer_correctness,\n",
    "        context_recall,\n",
    "        context_precision\n",
    "    ]\n",
    "    \n",
    "    # Convert the retrieved_chunk to a list of strings\n",
    "    contexts = [str(chunk) for chunk in model_output[\"retrieved_chunk\"]]\n",
    "    \n",
    "    qa_dataset = Dataset.from_dict(\n",
    "        {\n",
    "            \"question\": [question],\n",
    "            \"ground_truth\": [ground_truth],\n",
    "            \"answer\": [model_output[\"answer\"]],\n",
    "            \"contexts\": [contexts],  # Wrap contexts in another list\n",
    "        }\n",
    "    )\n",
    "    result = evaluate(qa_dataset, metrics=metric_modules,\n",
    "                      raise_exceptions=False)\n",
    "    return replace_nan_in_dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def tonic_validate_score(question: str, ground_truth: str, model_output: dict) -> dict:\n",
    "    from tonic_validate import Benchmark, ValidateScorer\n",
    "    from tonic_validate.metrics import DuplicationMetric\n",
    "\n",
    "    metric_modules = [DuplicationMetric()]\n",
    "\n",
    "    def get_llm_response(question):\n",
    "        return {\n",
    "            \"llm_answer\": model_output['answer'],\n",
    "            \"llm_context_list\": (\n",
    "                [model_output['retrieved_chunk']]\n",
    "                if isinstance(model_output['retrieved_chunk'], str)\n",
    "                else model_output['retrieved_chunk']\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    benchmark = Benchmark(questions=[question], answers=[ground_truth])\n",
    "    scorer = ValidateScorer(metrics=metric_modules)\n",
    "    run = scorer.score(benchmark, get_llm_response)\n",
    "    return run.run_data[0].scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Model: meta-llama/Meta-Llama-3-70B-Instruct-Turbo\n",
      "Question: What are the steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching?\n",
      "Question: How is the sense of spaciousness addressed in the design of habitats for the colony?\n",
      "Question: What is the importance of atmospheric pressure in large colonies in space?\n",
      "Question: How does the expense of providing human workers encourage reliance on automation and the push for extreme reliability and maintainability in space commercial ventures?\n",
      "Question: What are some potential benefits of long-term development in space?\n",
      "According to the text, the steps involved in producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching, are:\n",
      "\n",
      "1. The lunar soil is melted in a solar furnace at a temperature of 2000 K and then quenched in water to form a glass.\n",
      "2. The glass is ground to 65 mesh.\n",
      "3. The ground glass is leached with sulfuric acid.\n",
      "___________________________\n",
      "Atmospheric pressure is important in large colonies in space because it is necessary to maintain life processes adequately, and a total pressure of 36 kPa with 50% oxygen is considered practical for fire protection and suitable for human habitation.\n",
      "___________________________\n",
      "The sense of spaciousness is addressed in the design of habitats for the colony by providing a range of options, including large and small, private and community spaces, long and short vistas, and flexible, manipulatable architecture that allows colonists to reshape the interior. Additionally, the design should provide large-scale vistas, limit views to prevent seeing the entire structure, and provide contact with the actual environment of space through access to zero gravity and views of the Earth, Moon, and stars.\n",
      "___________________________\n",
      "{\"concise\": 4}\n",
      "{\"concise\": 4}\n",
      "Some potential benefits of long-term development in space include:\n",
      "\n",
      "* A large favorable effect on communication and other Earth-sensing satellites\n",
      "* Ability to track and communicate with planes, ships, trains, trucks, buses, cars, and even people continuously\n",
      "* Ability to provide stability for communication satellites\n",
      "* Potential for direct broadcasting of radio and TV to Earth from orbit\n",
      "* Colonists could carry out servicing and ultimately build some of the communication satellites.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anishshah/Documents/GitHub/weave/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n",
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n",
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text does not explicitly answer this question. However, it can be inferred that the expense of providing human workers is high, as the productivity of humans in space is difficult to estimate and is affected by the zero-g and high-vacuum environment. The use of remote operation and automation (e.g., the extraction plant is operated remotely) may be a way to reduce the cost and risk associated with human labor in space.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "\u001b[AError in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating:  20%|██        | 1/5 [00:10<00:40, 10.14s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "Evaluating:  60%|██████    | 3/5 [00:12<00:07,  3.51s/it]Runner in Executor raised an exception\n",
      "Runner in Executor raised an exception\n",
      "Evaluating:  80%|████████  | 4/5 [00:12<00:02,  2.39s/it]Runner in Executor raised an exception\n",
      "Evaluating: 100%|██████████| 5/5 [00:13<00:00,  2.61s/it]\n",
      "/Users/anishshah/Documents/GitHub/weave/.venv/lib/python3.12/site-packages/ragas/evaluation.py:296: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n",
      "Runner in Executor raised an exception\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:15<00:00,  3.08s/it]\n",
      "/Users/anishshah/Documents/GitHub/weave/.venv/lib/python3.12/site-packages/ragas/evaluation.py:296: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Runner in Executor raised an exception\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Evaluating: 100%|██████████| 5/5 [00:15<00:00,  3.09s/it]\n",
      "Evaluating: 100%|██████████| 5/5 [00:15<00:00,  3.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 16912.52it/s]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 20460.02it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:16<00:00,  3.35s/it]\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 13934.56it/s]\n",
      "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_judge_scorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'concise'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.4</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ragas_score'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'faithfulness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7428571428571429</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_relevancy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9535371396104324</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context_recall'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8444444444444444</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.59999999996</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tonic_validate_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'duplication_metric'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.478399801254272</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'llm_judge_scorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'concise'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.4\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'ragas_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'faithfulness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.7428571428571429\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'answer_relevancy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.9535371396104324\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'context_recall'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.8444444444444444\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'context_precision'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.59999999996\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'tonic_validate_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'duplication_metric'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.2\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m5.478399801254272\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Model: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\n",
      "Question: How is the sense of spaciousness addressed in the design of habitats for the colony?\n",
      "Question: How does the expense of providing human workers encourage reliance on automation and the push for extreme reliability and maintainability in space commercial ventures?\n",
      "Question: What are some potential benefits of long-term development in space?\n",
      "Question: What is the importance of atmospheric pressure in large colonies in space?\n",
      "Question: What are the steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching?\n",
      "Improved communication and Earth-sensing satellites, direct broadcasting of radio and TV to Earth, and reduced costs for power and stability in space.\n",
      "___________________________\n",
      "Fire protection is practical in an atmosphere with a total pressure of 36 kPa.\n",
      "___________________________\n",
      "The sense of spaciousness is addressed by providing a large-scale habitat, limiting the colonist's view to prevent seeing the entire structure at once, and allowing for convenient access to zero-gravity regions and views of the Earth, Moon, and stars.\n",
      "___________________________\n",
      "The steps involved in producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching, are:\n",
      "\n",
      "1. The glass from the quenching process is ground to 65 mesh.\n",
      "2. The ground glass is then leached with sulfuric acid.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}The expense of providing human workers in space is high due to the need for life support systems, habitats, and transportation to and from the space environment. This high expense encourages reliance on automation to reduce labor costs. Additionally, the difficulty and expense of accessing and repairing equipment in space emphasizes the need for extreme reliability and maintainability.\n",
      "___________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n",
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[AError in WeaveTracer.on_chain_start callback: KeyError('inputs')\n",
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n",
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Evaluating:  20%|██        | 1/5 [00:07<00:28,  7.17s/it]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60%|██████    | 3/5 [00:08<00:05,  2.51s/it]\n",
      "\u001b[A\n",
      "\n",
      "Evaluating:  80%|████████  | 4/5 [00:11<00:02,  2.44s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:17<00:00,  3.47s/it]\n",
      "Runner in Executor raised an exception\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:17<00:00,  3.54s/it]\n",
      "/Users/anishshah/Documents/GitHub/weave/.venv/lib/python3.12/site-packages/ragas/evaluation.py:296: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:17<00:00,  3.57s/it]\n",
      "\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 3086.32it/s]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 540.57it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]\n",
      "\n",
      "\n",
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:20<00:00,  4.05s/it]\n",
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "\n",
      "\n",
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 16384.00it/s]\n",
      "Runner in Executor raised an exception\n",
      "Evaluating: 100%|██████████| 5/5 [00:22<00:00,  4.47s/it]\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]\n",
      "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_judge_scorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'concise'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ragas_score'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'faithfulness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_relevancy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9110223092272138</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3308162385107881</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context_recall'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8444444444444444</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.79999999994</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tonic_validate_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'duplication_metric'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5518641471862793</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'llm_judge_scorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'concise'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m4.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'ragas_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'faithfulness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.9\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'answer_relevancy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.9110223092272138\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.3308162385107881\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'context_recall'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.8444444444444444\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'context_precision'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.79999999994\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'tonic_validate_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'duplication_metric'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m1.5518641471862793\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Model: Snowflake/snowflake-arctic-instruct\n",
      "Question: How is the sense of spaciousness addressed in the design of habitats for the colony?\n",
      "Question: What is the importance of atmospheric pressure in large colonies in space?\n",
      "Question: What are some potential benefits of long-term development in space?\n",
      "Question: What are the steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching?\n",
      "Question: How does the expense of providing human workers encourage reliance on automation and the push for extreme reliability and maintainability in space commercial ventures?\n",
      " Atmospheric pressure is important in large colonies in space as it ensures life processes are adequately maintained, prevents unusual forms of decompression, and provides a greater safety margin during accidental pressure drops or oxygen dilution by inert gases. The total pressure of the atmosphere should be practical, with half of it being oxygen, as seen in environments like Denver, Colorado. This allows for fire protection and the sustenance of necessary oxygen levels in the blood.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Potential benefits of long-term development in space include advancements in automation, materials technology, and other technological innovations, which may drive the progress of space colonization more rapidly and on a larger scale than currently anticipated. Additionally, space colonization can have a favorable effect on communication and Earth-sensing satellites, leading to improvements in data-link applications, tracking, and broadcasting. It may also provide solutions for energy production through space-based power systems. However, it is essential to address the potential challenges and risks associated with space colonization, such as health risks from high-energy radiation and the psychological impact of long-term space travel.\n",
      "___________________________\n",
      " The steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching, are as follows:\n",
      "\n",
      "1. The lunar soil is melted in a solar furnace at a temperature of 2000 K.\n",
      "2. The molten soil is then quenched in water to form a glass.\n",
      "3. The glass is ground to 65 mesh.\n",
      "4. The ground glass is leached with sulfuric acid.\n",
      "\n",
      "These steps are part of the overall process sequence to produce aluminum from lunar soil, which includes additional steps such as separation, centrifuging, condensation, and precipitation.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n",
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The expense of providing human workers in space encourages reliance on automation and the push for extreme reliability and maintainability in space commercial ventures because it is more cost-effective to use machines and systems that require minimal human intervention. This is due to the high costs associated with transporting and supporting human workers in space, as well as the risks involved in relying on humans for complex tasks. By using automated systems, space ventures can save on labor costs and minimize the need for human intervention, thereby increasing efficiency and reducing the risk of errors or malfunctions. Additionally, the harsh and unforgiving environment of space demands high levels of reliability and maintainability in the equipment and systems used, further driving the push for automation and extreme reliability in space commercial ventures.\n",
      "___________________________\n",
      " The sense of spaciousness is addressed in the design of habitats for the colony by providing a variety of spaces, including both large and small, private and community spaces, and long vistas and short ones. The architecture is flexible and manipulatable, allowing colonists to reshape the interior according to their individual wants. Additionally, the building system is designed to be lightweight, easily mass-produced, and capable of fast and efficient erection, using modular components to achieve a variety of shapes and combinations. To offset the undesirable effects of artificiality, large-scale vistas are provided by designing the habitat large enough so that the entire structure cannot be seen in a single scan, and access to regions of zero gravity and views of the Earth, Moon, and stars are made available. On a smaller scale, the presence of live, growing things such as vegetation, children playing, and animals contribute to reducing the artificiality of the interior. The amount of area allocated per person also plays a role in addressing the sense of spaciousness, as it determines the population density and limits services and facilities provided to the inhabitants. A minimum of 40 m^2 of projected area per inhabitant is recommended to minimize the sense of crowding while still providing needed services.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[AError in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "\n",
      "\n",
      "\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "Evaluating:  20%|██        | 1/5 [00:07<00:29,  7.42s/it]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Evaluating:  60%|██████    | 3/5 [00:09<00:05,  2.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "Evaluating:  80%|████████  | 4/5 [00:10<00:02,  2.05s/it]Runner in Executor raised an exception\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:13<00:00,  2.61s/it]\n",
      "/Users/anishshah/Documents/GitHub/weave/.venv/lib/python3.12/site-packages/ragas/evaluation.py:296: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n",
      "Evaluating: 100%|██████████| 5/5 [00:15<00:00,  3.05s/it]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]\n",
      "\n",
      "\n",
      "\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:17<00:00,  3.55s/it]\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runner in Executor raised an exception\n",
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runner in Executor raised an exception\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:29<00:00,  5.80s/it]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 12865.96it/s]\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runner in Executor raised an exception\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:33<00:00,  6.64s/it]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_judge_scorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'concise'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.6</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ragas_score'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'faithfulness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_relevancy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9387264695712304</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.142868741763214</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context_recall'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6444444444444445</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.79999999995</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tonic_validate_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'duplication_metric'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.42079267501831</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'llm_judge_scorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'concise'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.6\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'ragas_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'faithfulness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.6\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'answer_relevancy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.9387264695712304\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.142868741763214\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'context_recall'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.6444444444444445\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'context_precision'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.79999999995\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'tonic_validate_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'duplication_metric'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.2\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m4.42079267501831\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Model: mistralai/Mixtral-8x22B-Instruct-v0.1\n",
      "Question: What is the importance of atmospheric pressure in large colonies in space?\n",
      "Question: How does the expense of providing human workers encourage reliance on automation and the push for extreme reliability and maintainability in space commercial ventures?\n",
      "Question: What are the steps involved in the process of producing aluminum from lunar soil, specifically in regards to glass grinding and acid leaching?\n",
      "Question: How is the sense of spaciousness addressed in the design of habitats for the colony?\n",
      "Question: What are some potential benefits of long-term development in space?\n",
      " The process involves melting lunar soil in a solar furnace at 2000 K, then quenching it in water to form a glass. The glass is then separated in a centrifuge and the steam is condensed in radiators. The glass is ground to 65 mesh and leached with sulfuric acid. The pregnant solution containing aluminum sulfate is then separated from the waste material in a centrifuge.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Atmospheric pressure is important for fire protection and sustaining life processes in large space colonies. In this context, a mix of 50% oxygen and 50% nitrogen with a total pressure of 36 kPa is considered practical, with half of it being oxygen.\n",
      "___________________________\n",
      "{\"concise\": 4}\n",
      " The high cost of transporting and maintaining human workers in space encourages the use of automation. The need for extreme reliability and maintainability arises from the fact that repairs and replacements in space are expensive and difficult, making it more cost-effective to invest in highly reliable and easily maintainable systems.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The sense of spaciousness is addressed by providing large-scale vistas, making the habitat large enough to lessen the sense of artificiality. Additionally, some parts of the habitat are designed to be out of sight of others, and contact with the actual environment of space is provided through convenient access to regions of zero gravity and views of the Earth, the Moon, and stars.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Some potential benefits of long-term development in space include advancements in automation, materials technology, and improved communication and Earth-sensing satellites. Space colonization could also lead to direct broadcasting of radio and TV from orbit, once low-cost power in space is available. Additionally, colonists could perform servicing and construction of satellites.\n",
      "___________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in WeaveTracer.on_chain_start callback: KeyError('inputs')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"concise\": 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "Runner in Executor raised an exception\n",
      "Evaluating: 100%|██████████| 5/5 [00:02<00:00,  1.71it/s]\n",
      "/Users/anishshah/Documents/GitHub/weave/.venv/lib/python3.12/site-packages/ragas/evaluation.py:296: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n",
      "Evaluating:  20%|██        | 1/5 [00:07<00:29,  7.47s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 14716.86it/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Evaluating:  60%|██████    | 3/5 [00:12<00:07,  3.64s/it]Runner in Executor raised an exception\n",
      "Evaluating: 100%|██████████| 5/5 [00:12<00:00,  2.42s/it]\n",
      "/Users/anishshah/Documents/GitHub/weave/.venv/lib/python3.12/site-packages/ragas/evaluation.py:296: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "Scoring responses:   0%|          | 0/1 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "\n",
      "Evaluating: 100%|██████████| 5/5 [00:13<00:00,  2.67s/it]\n",
      "\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 9868.95it/s]\n",
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[ARunner in Executor raised an exception\n",
      "Evaluating: 100%|██████████| 5/5 [00:16<00:00,  3.25s/it]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runner in Executor raised an exception\n",
      "Evaluating: 100%|██████████| 5/5 [00:20<00:00,  4.20s/it]\n",
      "Retrieving responses: 100%|██████████| 1/1 [00:00<00:00, 15363.75it/s]\n",
      "Scoring responses: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m5\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_judge_scorer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'concise'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.0</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ragas_score'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'faithfulness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6414285714285715</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_relevancy'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7416256940511602</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'answer_correctness'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context_recall'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.79999999995</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tonic_validate_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'duplication_metric'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.270722675323486</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'llm_judge_scorer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'concise'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m4.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'ragas_score'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'faithfulness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.6414285714285715\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'answer_relevancy'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.7416256940511602\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'answer_correctness'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'context_recall'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.8\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'context_precision'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.79999999995\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'tonic_validate_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'duplication_metric'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m0.2\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.270722675323486\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\"meta-llama/Meta-Llama-3-70B-Instruct-Turbo\",\n",
    "          \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "          \"Snowflake/snowflake-arctic-instruct\",\n",
    "          \"mistralai/Mixtral-8x22B-Instruct-v0.1\"]\n",
    "for model in models:\n",
    "    rag_model = SpaceRAGModel(model=model)\n",
    "    evaluation = Evaluation(dataset=small_questions, scorers=[\n",
    "    llm_judge_scorer,\n",
    "    ragas_score,\n",
    "    tonic_validate_score\n",
    "])\n",
    "    print(f\"RAG Model: {model}\")\n",
    "    await evaluation.evaluate(rag_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
