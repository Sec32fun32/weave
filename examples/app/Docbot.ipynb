{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import weave\n",
    "weave.use_frontend_devmode()\n",
    "from weave.ecosystem import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7192c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_basic_10 = [\n",
    "    \"What is the purpose of experiment tracking in machine learning, and how does the Weights & Biases platform facilitate this process?\",\n",
    "    \"How does the Weights & Biases platform help to improve the reproducibility and transparency of machine learning experiments?\",\n",
    "    \"What are some of the key features of the Weights & Biases platform that make it a popular choice for experiment tracking in machine learning?\",\n",
    "    \"How does the Weights & Biases platform allow users to compare and evaluate the performance of different machine learning models?\",\n",
    "    \"What are some of the benefits of using Weights & Biases for experiment tracking, and how do these benefits translate into improved outcomes for machine learning projects?\",\n",
    "    \"How does Weights & Biases enable collaboration and sharing of experiments across teams working on different machine learning projects?\",\n",
    "    \"Can the Weights & Biases platform be integrated with other tools commonly used in machine learning workflows, such as Jupyter notebooks or TensorBoard?\",\n",
    "    \"What are some best practices for using Weights & Biases for experiment tracking, and how can users maximize the platform's potential?\",\n",
    "    \"How does Weights & Biases help users to identify and troubleshoot issues that may arise during the training and evaluation of machine learning models?\",\n",
    "    \"How does Weights & Biases help users to optimize the hyperparameters of machine learning models, and what strategies can be employed to maximize the effectiveness of this feature?\"\n",
    "]\n",
    "questions = weave.save(gpt4_basic_10[:2], 'questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a68bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uses StringHistogram by default. Prefer Each or Table\n",
    "#questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import (\n",
    "    MarkdownTextSplitter,\n",
    "    PythonCodeTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "# Get markdown files from our docs repo\n",
    "\n",
    "# Checkout of our docs repo: https://github.com/wandb/docodile/\n",
    "DOC_DIR = '/Users/shawn/code2/docodile'\n",
    "DOC_SUFFIX = '.md'\n",
    "\n",
    "docs = []\n",
    "for file in pathlib.Path(DOC_DIR).glob('**/*' + DOC_SUFFIX):\n",
    "    with file.open('r') as f:\n",
    "        # store them as langchain Document objects\n",
    "        docs.append(Document(page_content=f.read(), metadata={'path': file.name}))\n",
    "docs = MarkdownTextSplitter().split_documents(docs)\n",
    "docs = TokenTextSplitter().split_documents(docs)\n",
    "\n",
    "docs = weave.save(docs, 'wandb-docs')\n",
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b583ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: crash due to a panel error, need to fix auto table state to work on Object Type\n",
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a3a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import VectorStore, FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = FAISS.from_documents(weave.use(docs), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a706ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff you can do:\n",
    "#   - .similarity_search(<query>)\n",
    "#     - but currently there is a crash because Row.Group tries to render and fails. Need to switch the\n",
    "#       panel to Table and then change column to row.__getattr__('page_content')\n",
    "#   - .document_embeddings\n",
    "#     - this gets the embeddings out of FAISS, and also performs FAISS' k-means with 20 clusters\n",
    "#     - switch to projection.plot\n",
    "# TODO:\n",
    "#   - no default panel!\n",
    "#   - fix Row.Group crash\n",
    "#   - automatically show Table instead of Row.Group\n",
    "#   - make PanelTable automatically render Object correctly.\n",
    "#   - make PanelObject handle Objects\n",
    "#   - fix __getattr__ rendering\n",
    "#   - give control over k for k-means\n",
    "#   - figure out dragging region on embeddings view to perform drilldown (won't work because of projector wrapping)\n",
    "weave.show(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "model_gpt_35_temp07 = RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.7),\n",
    "        chain_type='stuff',\n",
    "        retriever=vector_store.as_retriever()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9217d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with langchain\n",
    "model_gpt_35_temp07.run('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with weave\n",
    "model = weave.save(model_gpt_35_temp07)\n",
    "#model.run('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ae43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.7),\n",
    "        chain_type='stuff',\n",
    "        retriever=vector_store.as_retriever()\n",
    "    ),\n",
    "    RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.2),\n",
    "        chain_type='stuff',\n",
    "        retriever=vector_store.as_retriever()\n",
    "    )\n",
    "]\n",
    "models = weave.save(models, 'docbot-models')\n",
    "# TODO: can't view this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run multiple models at once\n",
    "# TODO: this is the wrong view, need to show which model it was as well!\n",
    "models.run('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can map over questions\n",
    "# TODO:\n",
    "#   - crash due to document size. Need to do a split stage1\n",
    "#   - default output format is wrong. Want table of Question v. Model\n",
    "#questions.map(lambda q: models.run(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This defines the whole thing using Weave ops\n",
    "# TODO:\n",
    "#   - how do we naturally get from the style above where we use langchain directly\n",
    "#     and save to weave, to here where we use weave ops to construct everything?\n",
    "#     (I think the answer has to do with object constructors!)\n",
    "#   - what if we want to save our own evaluations instead of letting Weave do it?\n",
    "#     (ie make standard manual flow work)\n",
    "vector_store = langchain.faiss_from_documents(docs, langchain.openai_embeddings())\n",
    "llm = langchain.chat_openai('gpt-3.5-turbo', 0.7)\n",
    "qa = langchain.retrieval_qa_from_chain_type(llm, 'stuff', vector_store)\n",
    "qa.run('what is weave?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#   - use latest\n",
    "#   - fix projections\n",
    "#   - change how projector works\n",
    "#   - super ugly projection config\n",
    "#   - why is similarity search so slow now?\n",
    "#     - because the openai API is being slow, and we need to embed the query _and_ we can't cache the\n",
    "#       query embedding step because it happens down in langchain. Better to build this stuff up in a Weave\n",
    "#       way!\n",
    "#   - make projection drilldown\n",
    "#   - make table of question v model\n",
    "#   - auto table for projection output does source.cluster, but it seems the . notation doesn't work\n",
    "#     in weave1 for some reason? ['source']['cluster'] is fine\n",
    "#   - wordclouds / stacey plots\n",
    "#   - selection on plot gives us the output plot data, not the input data! so we can't see anything useful\n",
    "#   - selection on plot doesn't \"stick\"\n",
    "\n",
    "\n",
    "weave.panels.Board(\n",
    "    vars={\n",
    "        'documents': docs,\n",
    "        'questions': questions.limit(2),\n",
    "        'embeddings': langchain.openai_embeddings(),\n",
    "        'vector_store': lambda embeddings, documents: langchain.faiss_from_documents(documents, embeddings),\n",
    "        'doc_embeddings': lambda vector_store: vector_store.document_embeddings(),\n",
    "        'models': lambda vector_store: weave.ops.make_list(\n",
    "            a=langchain.retrieval_qa_from_chain_type(langchain.chat_openai('gpt-3.5-turbo', 0.2), 'stuff', vector_store),\n",
    "            b=langchain.retrieval_qa_from_chain_type(langchain.chat_openai('gpt-3.5-turbo', 0.7), 'stuff', vector_store),\n",
    "        ),\n",
    "        'projection': lambda doc_embeddings: doc_embeddings.projection2D(\n",
    "                                                                  'pca',\n",
    "                                                                  'single',\n",
    "                                                                  ['embedding'],\n",
    "                                                                  {'pca': {},\n",
    "                                                                   'tsne': {\n",
    "                                                                       'perplexity': 30,\n",
    "                                                                       'learningRate': 10,\n",
    "                                                                       'iterations': 25\n",
    "                                                                   },\n",
    "                                                                   'umap': {\n",
    "                                                                       'neighbors': 15,\n",
    "                                                                       'minDist': 0.1,\n",
    "                                                                       'spread': 1.0\n",
    "                                                                   }\n",
    "                                                                  }),\n",
    "        'eval_results': lambda questions, models: questions.map(lambda question: models.run(question))\n",
    "    },\n",
    "    panels=[      \n",
    "        weave.panels.BoardPanel(\n",
    "            lambda documents: weave.panels.Table(documents,\n",
    "                                                 columns=[\n",
    "                                                     lambda doc: doc.page_content,\n",
    "                                                     lambda doc: doc.metadata['path']\n",
    "                                                 ]),\n",
    "            layout=weave.panels.BoardPanelLayout(x=0, y=0, w=12, h=6)\n",
    "        ),\n",
    "        weave.panels.BoardPanel(\n",
    "            lambda vector_store: weave.panels.Table(vector_store.similarity_search('weave'),\n",
    "                                                    columns=[\n",
    "                                                     lambda doc: doc.page_content,\n",
    "                                                     lambda doc: doc.metadata['path']  \n",
    "                                                    ]),\n",
    "            layout=weave.panels.BoardPanelLayout(x=12, y=0, w=12, h=6)\n",
    "        ),\n",
    "        weave.panels.BoardPanel(\n",
    "            id='docs_projection',\n",
    "            panel=lambda projection: weave.panels.Plot(\n",
    "                projection,\n",
    "                x=lambda row: row['projection.x'],\n",
    "                y=lambda row: row['projection.y'],\n",
    "                color=lambda row: row['source.cluster']\n",
    "            ),\n",
    "            layout=weave.panels.BoardPanelLayout(x=0, y=6, w=12, h=12)\n",
    "        ),\n",
    "        weave.panels.BoardPanel(\n",
    "            lambda docs_projection: docs_projection.rows_selected(),\n",
    "            layout=weave.panels.BoardPanelLayout(x=12, y=6, w=12, h=12)\n",
    "        ),\n",
    "        weave.panels.BoardPanel(\n",
    "            lambda eval_results: weave.panels.Table(eval_results),\n",
    "            layout=weave.panels.BoardPanelLayout(x=0, y=18, w=24, h=12)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
