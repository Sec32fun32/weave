{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f47d996",
   "metadata": {},
   "source": [
    "# Compare LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6f645",
   "metadata": {},
   "source": [
    "Creating programs that rely on LLMs is an iterative process so we need a workflow to compare each new pipeline/prompt/technique systemtically.\n",
    "\n",
    "In this tutorial, we'll experiment on models and create a workflow using Weave to:\n",
    "- Run the same evaluation set every new program and store responses, token count, etc.\n",
    "- Display a table with any two pipelines responses side-by-side with the ability to page through examples and  group/sort/filter with the UI\n",
    "- Display a bar chart to compare each metric, like token count sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506aec5",
   "metadata": {},
   "source": [
    "# Evaluate different pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de3c7b",
   "metadata": {},
   "source": [
    "So that we're comparing apples with apples, we'll create an evaluation dataset to run our pipelines on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3f00181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "weave.use_frontend_devmode()\n",
    "import random\n",
    "\n",
    "classes = ['positive', 'negative', 'neutral']\n",
    "prompts = [\"I absolutely love this product!\", \n",
    "           \"I'm really disappointed with this service.\", \n",
    "           \"The movie was just average.\"]\n",
    "labels = ['positive', 'negative', 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c84f5",
   "metadata": {},
   "source": [
    "For this example, we'll just mock a few pipelines and this will also save us from using up our LLM budget while we build out this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85837eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(prompt: str) -> str:\n",
    "    latency = random.uniform(0, 10)\n",
    "    tokens = random.choice(range(0, 10))\n",
    "    response = random.choice(classes)\n",
    "    return response, latency, tokens\n",
    "\n",
    "pipeline_1 = pipeline_2 = pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c11f0",
   "metadata": {},
   "source": [
    "Now that we have our pipelines defined, we can run them through our pipelines and capture the responses. Here is where we'll capture other metrics we care about like latency and token count so we can use them for comparison later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2f9b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pipeline, pipeline_name):\n",
    "    outs = []\n",
    "    for prompt, label in zip(prompts, labels):\n",
    "        response, latency, tokens = pipeline(prompt)\n",
    "        outs.append({'label': label,\n",
    "                     'prompt': prompt,\n",
    "                     'response': response,\n",
    "                     'latency': latency,\n",
    "                     'tokens': tokens})\n",
    "    return weave.save(outs, name=pipeline_name)\n",
    "\n",
    "pipeline_1_w = evaluate(pipeline_1, 'pipeline_1')\n",
    "pipeline_2_w = evaluate(pipeline_2, 'pipeline_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1075426e",
   "metadata": {},
   "source": [
    "We use `weave.save(<responses and metrics>, name=<name>` to save them to weave, we're choosing a model name ourself and we're collecting our responses and metrics in a list of Python dictionaries.\n",
    "\n",
    "Now Weave will intelligently decides how to display our data so can view `model_1_w` in a `weave` table. In a notebook, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93e7eb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-pipeline_1%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1702d8280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_1_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c347f0b",
   "metadata": {},
   "source": [
    "In this table, you can page through examples, filter results and even create new columns by using data in other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274b9a5",
   "metadata": {},
   "source": [
    "# Join Prediction Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30809579",
   "metadata": {},
   "source": [
    "Because we want to compare our pipelines for each prompt, we'll use a `weave` Op (operation) to join the two tables on the `prompt`. We'll give the pipelines aliases `1` & `2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b1077c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-list%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1702dab60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined = weave.ops.join_2(\n",
    "    pipeline_1_w,\n",
    "    pipeline_2_w,\n",
    "    lambda row: row['prompt'], \n",
    "    lambda row: row['prompt'],\n",
    "    '1',\n",
    "    '2',\n",
    "    False,\n",
    "    False)\n",
    "\n",
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a8cfa",
   "metadata": {},
   "source": [
    "We only want to display our prompts, labels, and each model's response, so we'll need to use `weave.panels.Table` to do so. The `columns` argument may look a bit strange, but it's a way for us to define which columns are used in the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b8b4e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-table0%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1702dc280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = weave.panels.Table(\n",
    "    joined,\n",
    "    columns=[\n",
    "        lambda row: row[\"1.label\"],\n",
    "        lambda row: row[\"1.prompt\"],\n",
    "        lambda row: row[\"1.response\"],\n",
    "        lambda row: row[\"1.response\"] == row[\"1.label\"],\n",
    "        lambda row: row[\"2.response\"],\n",
    "        lambda row: row[\"2.response\"] == row[\"2.label\"],\n",
    "    ],\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecc1b3",
   "metadata": {},
   "source": [
    "Now we have a joined table, with only the columns we want displayed, and even some computed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c07756",
   "metadata": {},
   "source": [
    "## Compare average latency & token count\n",
    "\n",
    "We also want a bar chart to compare our metrics so we'll create a dictionary for our computed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2be4a2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-typedDict%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1702dca60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latency_bar = weave.ops.dict_(\n",
    "    pipeline_1=joined[\"1.latency\"].avg(),\n",
    "    pipeline_2=joined[\"2.latency\"].avg(),\n",
    ")\n",
    "latency_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cd450",
   "metadata": {},
   "source": [
    "This might seem a bit magic, but it's the same as we saw above, `weave` makes a best guess how to display your data. Here, we created a dict like `{'pipeline_1': metric_a, 'pipeline_2': metric_b}` and it chooses to display it as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5a442d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-typedDict%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1702db700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_count_bar = weave.ops.dict_(\n",
    "    pipeline_1=joined[\"1.tokens\"].sum(),\n",
    "    pipeline_2=joined[\"2.tokens\"].sum(),\n",
    ")\n",
    "token_count_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e004ddc",
   "metadata": {},
   "source": [
    "Again, we created a dictionary with weave, and it knew to display it as a bar chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4321f",
   "metadata": {},
   "source": [
    "## Putting it all together in a Board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f9e84",
   "metadata": {},
   "source": [
    "Because we want to easily jump between comparing different models, we'll need some way to change which models we're comparing. To do this, we'll use a weave Board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ac87a",
   "metadata": {},
   "source": [
    "Weave Boards can have variables `vars` which you can change dynamically to make your panels and plots update. \n",
    "Here, we'll define which models we're comparing and we can change the local artifact path to get new models. We'll put each of our panels in a `BoardPanel` and we'll define the layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a1abb5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-Group0%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1702f2d40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weave.panels.Board(\n",
    "    vars={\n",
    "        \"pipeline_1\": pipeline_1_w,\n",
    "        \"pipeline_2\": pipeline_2_w,\n",
    "        \"joined\": lambda pipeline_1, pipeline_2: \n",
    "        weave.ops.join_2(\n",
    "            pipeline_1, \n",
    "            pipeline_2,\n",
    "            lambda row: row['prompt'], \n",
    "            lambda row: row['prompt'],\n",
    "            '1',\n",
    "            '2',\n",
    "            False,\n",
    "            False)                                                 \n",
    "            },\n",
    "    panels=[\n",
    "        weave.panels.BoardPanel(\n",
    "            lambda joined: weave.panels.Table(\n",
    "                                joined,\n",
    "                                columns=[\n",
    "                                    lambda row: row[\"1.label\"],\n",
    "                                    lambda row: row[\"1.prompt\"],\n",
    "                                    lambda row: row[\"1.response\"],\n",
    "                                    lambda row: row[\"1.response\"] == row[\"1.label\"],\n",
    "                                    lambda row: row[\"2.response\"],\n",
    "                                    lambda row: row[\"2.response\"] == row[\"2.label\"],\n",
    "                                ],\n",
    "                            ),\n",
    "            layout=weave.panels.BoardPanelLayout(x=0, y=0, w=24, h=9)\n",
    "        ),\n",
    "         weave.panels.BoardPanel(\n",
    "            lambda joined: weave.ops.dict_(\n",
    "                                pipeline_1=joined[\"1.tokens\"].sum(),\n",
    "                                pipeline_2=joined[\"2.tokens\"].sum(),\n",
    "                            ),\n",
    "             layout=weave.panels.BoardPanelLayout(x=0, y=9, w=12, h=8)\n",
    "        ),\n",
    "        weave.panels.BoardPanel(\n",
    "            lambda joined: weave.ops.dict_(\n",
    "                                pipeline_1=joined[\"1.latency\"].avg(),\n",
    "                                pipeline_2=joined[\"2.latency\"].avg(),\n",
    "                            ),\n",
    "             layout=weave.panels.BoardPanelLayout(x=12, y=9, w=12, h=8)\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88665131",
   "metadata": {},
   "source": [
    "You can now open the Board in a new tab to make it full screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e40dcc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "And that's it. We've created a `weave Board` to compare our pipeline responses, token counts and latency. We've seen how `weave` intelligently decides how to display data, whether that's in a table, bar chart or some other panel. We've learned how to define `panels` ourself, and define computations using weave `Ops`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
