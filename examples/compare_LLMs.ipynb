{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f47d996",
   "metadata": {},
   "source": [
    "# Compare LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6f645",
   "metadata": {},
   "source": [
    "Creating programs that rely on LLMs is an iterative process so we need a workflow to compare each new pipeline/prompt/technique systemtically.\n",
    "\n",
    "In this tutorial, we'll experiment on models and create a workflow using Weave to:\n",
    "- Run the same evaluation set every new program and store responses, token count, etc.\n",
    "- Display a table with any two pipelines responses side-by-side with the ability to page through examples and  group/sort/filter with the UI\n",
    "- Display a bar chart to compare each metric, like token count sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506aec5",
   "metadata": {},
   "source": [
    "# Evaluate different pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de3c7b",
   "metadata": {},
   "source": [
    "So that we're comparing apples with apples, we'll create an evaluation dataset to run our pipelines on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f00181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "import random\n",
    "\n",
    "classes = ['positive', 'negative', 'neutral']\n",
    "prompts = [\"I absolutely love this product!\", \n",
    "           \"I'm really disappointed with this service.\", \n",
    "           \"The movie was just average.\"]\n",
    "labels = ['positive', 'negative', 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729616ea",
   "metadata": {},
   "source": [
    "TODO: save and load with weave so the data is versioned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c84f5",
   "metadata": {},
   "source": [
    "For this example, we'll just mock a few pipelines and this will also save us from using up our LLM budget while we build out this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85837eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(prompt: str) -> str:\n",
    "    latency = random.uniform(0, 10)\n",
    "    tokens = random.choice(range(0, 10))\n",
    "    response = random.choice(classes)\n",
    "    return response, latency, tokens\n",
    "\n",
    "pipeline_1 = pipeline_2 = pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c11f0",
   "metadata": {},
   "source": [
    "Now that we have our pipelines defined, we can run them through our pipelines and capture the responses. Here is where we'll capture other metrics we care about like latency and token count so we can use them for comparison later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2f9b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pipeline, pipeline_name):\n",
    "    outs = []\n",
    "    for prompt, label in zip(prompts, labels):\n",
    "        response, latency, tokens = pipeline(prompt)\n",
    "        outs.append({'label': label,\n",
    "                     'prompt': prompt,\n",
    "                     'response': response,\n",
    "                     'latency': latency,\n",
    "                     'tokens': tokens})\n",
    "    return weave.save(outs, name=pipeline_name)\n",
    "\n",
    "pipeline_1_w = evaluate(pipeline_1, 'pipeline_1')\n",
    "pipeline_2_w = evaluate(pipeline_2, 'pipeline_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1075426e",
   "metadata": {},
   "source": [
    "We use `weave.save(<responses and metrics>, name=<name>` to save them to weave, we're choosing a model name ourself and we're collecting our responses and metrics in a list of Python dictionaries.\n",
    "\n",
    "Now Weave will intelligently decides how to display our data so can view `model_1_w` in a `weave` table. In a notebook, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e7eb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:63830/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-pipeline_1%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2a5529900>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_1_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c347f0b",
   "metadata": {},
   "source": [
    "In this table, you can page through examples, filter results and even create new columns by using data in other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274b9a5",
   "metadata": {},
   "source": [
    "# Join Prediction Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30809579",
   "metadata": {},
   "source": [
    "Because we want to compare our pipelines for each prompt, we'll use a `weave` Op (operation) to join the two tables on the `prompt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7bef1a",
   "metadata": {},
   "source": [
    "TODO: Do this dynamically in the Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b1077c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:63830/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-res_w%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2ae4e7d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = weave.ops.join_2(\n",
    "    model_1_w, model_2_w,\n",
    "    lambda row: row['prompt'], \n",
    "    lambda row: row['prompt'],\n",
    "    'model_a',\n",
    "    'model_b',\n",
    "    False,\n",
    "    False)\n",
    "\n",
    "x = weave.use(res)\n",
    "res_w = weave.save(x, 'res_w')\n",
    "res_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a8cfa",
   "metadata": {},
   "source": [
    "We only want to display our prompts, labels, and each model's response, so we'll need to use `weave.panels.Table` to do so. The `columns` argument may look a bit strange, but it's a way for us to define which columns are used in the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b8b4e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:63830/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-table0%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2ae5009a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = weave.panels.Table(\n",
    "    res_w,\n",
    "    columns=[\n",
    "        lambda row: row[\"model_a.label\"],\n",
    "        lambda row: row[\"model_a.prompt\"],\n",
    "        lambda row: row[\"model_a.response\"],\n",
    "        lambda row: row[\"model_a.response\"] == row[\"model_a.label\"],\n",
    "        lambda row: row[\"model_b.response\"],\n",
    "        lambda row: row[\"model_b.response\"] == row[\"model_b.label\"],\n",
    "    ],\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecc1b3",
   "metadata": {},
   "source": [
    "Now we have a joined table, with only the columns we want displayed, and even some computed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c07756",
   "metadata": {},
   "source": [
    "We also want a bar chart to compare our metrics so we'll create a dictionary for our computed metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2be4a2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:63830/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-typedDict%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2abf4b100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latency_bar = weave.ops.dict_(\n",
    "    model_a=res_w[\"model_a.latency\"].avg(),\n",
    "    model_b=res_w[\"model_b.latency\"].avg(),\n",
    ")\n",
    "latency_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cd450",
   "metadata": {},
   "source": [
    "This might seem a bit magic, but it's the same as we saw above, `weave` makes a best guess how to display your data. Here, we created a dict like `{'model_a': metric_a, 'model_b': metric_b}` and it chooses to display it as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5a442d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:63830/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-typedDict%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x118913250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_count_bar = weave.ops.dict_(\n",
    "    model_a=res_w[\"model_a.tokens\"].sum(),\n",
    "    model_b=res_w[\"model_b.tokens\"].sum(),\n",
    ")\n",
    "token_count_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e004ddc",
   "metadata": {},
   "source": [
    "Again, we created a dictionary with weave, and it knew to display it as a bar chart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4321f",
   "metadata": {},
   "source": [
    "## Putting it all together in a Board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f9e84",
   "metadata": {},
   "source": [
    "Because we want to easily jump between comparing different models, we'll need some way to change which models we're comparing. To do this, we'll use a weave Board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ac87a",
   "metadata": {},
   "source": [
    "Weave Boards can have variables `vars` which you can change dynamically to make your panels and plots update. \n",
    "Here, we'll define which models we're comparing by name. We'll put each of our panels in a `BoardPanel` and we'll define the layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a1abb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:63830/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22any%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///dashboard-Group0%3Alatest/obj%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            allow=\"clipboard-write\"\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2ac932d40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weave.panels.Board(\n",
    "    vars={\n",
    "        \"res_w_0\": res_w                                                 \n",
    "    },\n",
    "    panels=[\n",
    "        weave.panels.BoardPanel(\n",
    "            lambda res_w_0: table,\n",
    "            layout=weave.panels.BoardPanelLayout(x=0, y=0, w=24, h=9)\n",
    "        ),\n",
    "         weave.panels.BoardPanel(\n",
    "            lambda res_w_0: token_count_bar,\n",
    "             layout=weave.panels.BoardPanelLayout(x=0, y=9, w=12, h=8)\n",
    "        ),\n",
    "        weave.panels.BoardPanel(\n",
    "            lambda res_w_0: latency_bar,\n",
    "             layout=weave.panels.BoardPanelLayout(x=12, y=9, w=12, h=8)\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e40dcc",
   "metadata": {},
   "source": [
    "And that's it. We've created a `weave Board` to compare our pipeline responses, token counts and latency. We've seen how `weave` intelligently decides how to display data, whether that's in a table, bar chart or some other panel. We've learned how to define `panels` ourself, and define computations using weave `Ops`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
