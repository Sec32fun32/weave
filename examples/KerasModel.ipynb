{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4e3073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "from weave.ecosystem import keras as weave_keras\n",
    "\n",
    "weave.use_frontend_devmode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66681df",
   "metadata": {},
   "source": [
    "# Train Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfd4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d23637e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%7B%22type%22%3A%20%22KerasModel%22%2C%20%22inputs_type%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%7B%22type%22%3A%20%22KerasTensor%22%2C%20%22shape%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%22none%22%2C%20%221%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%2C%20%22datatype_enum%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%207%7D%7D%7D%7D%2C%20%22outputs_type%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%7B%22type%22%3A%20%22KerasTensor%22%2C%20%22shape%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%22none%22%2C%20%221%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%2C%20%22datatype_enum%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%7D%7D%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///tmp/local-artifacts/KerasModel/6558c37f75b5b9d0a198d4a989ba9f3f%22%7D%2C%20%22val%22%3A%20%22local-artifact%3A///tmp/local-artifacts/KerasModel/6558c37f75b5b9d0a198d4a989ba9f3f%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1547c9430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ddtrace.internal.writer:failed to send traces to Datadog Agent at http://localhost:8126/v0.4/traces\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 407, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 446, in _send_payload\n",
      "    response = self._put(payload, headers)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 398, in _put\n",
      "    self._conn.request(\"PUT\", self._endpoint, data, headers)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1285, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1331, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1280, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1040, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 980, in send\n",
      "    self.connect()\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 946, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\", line 844, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\", line 832, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 559, in flush_queue\n",
      "    self._retry_upload(self._send_payload, encoded, n_traces)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 404, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 361, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x155a38850 state=finished raised ConnectionRefusedError>]\n"
     ]
    }
   ],
   "source": [
    "saved_text_model = weave.get(\"local-artifact:///tmp/local-artifacts/KerasModel/6558c37f75b5b9d0a198d4a989ba9f3f\")\n",
    "saved_text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbbf4f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.5092068314552307]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_text_model.val.predict([\"Asd\"]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "600cbcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%22number%22%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22op-call_string%22%2C%20%22inputs%22%3A%20%7B%22model%22%3A%20%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%7B%22type%22%3A%20%22KerasModel%22%2C%20%22inputs_type%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%7B%22type%22%3A%20%22KerasTensor%22%2C%20%22shape%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%22none%22%2C%20%221%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%2C%20%22datatype_enum%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%207%7D%7D%7D%7D%2C%20%22outputs_type%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%7B%22type%22%3A%20%22KerasTensor%22%2C%20%22shape%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%22none%22%2C%20%221%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%2C%20%22datatype_enum%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%7D%7D%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///tmp/local-artifacts/KerasModel/6558c37f75b5b9d0a198d4a989ba9f3f%22%7D%2C%20%22val%22%3A%20%22local-artifact%3A///tmp/local-artifacts/KerasModel/6558c37f75b5b9d0a198d4a989ba9f3f%22%7D%7D%7D%7D%2C%20%22input_str%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22string%22%2C%20%22val%22%3A%20%22single%20test%20string%20223%22%7D%2C%20%22val%22%3A%20%22single%20test%20string%20223%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1563214f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ddtrace.internal.writer:failed to send traces to Datadog Agent at http://localhost:8126/v0.4/traces\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 407, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 446, in _send_payload\n",
      "    response = self._put(payload, headers)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 398, in _put\n",
      "    self._conn.request(\"PUT\", self._endpoint, data, headers)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1285, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1331, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1280, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1040, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 980, in send\n",
      "    self.connect()\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 946, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\", line 844, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\", line 832, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 559, in flush_queue\n",
      "    self._retry_upload(self._send_payload, encoded, n_traces)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 404, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 361, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x156321250 state=finished raised ConnectionRefusedError>]\n"
     ]
    }
   ],
   "source": [
    "weave_keras.call_string(saved_text_model, \"single test string 223\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55cab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"weave_model_1\"\n",
    "\n",
    "default_config = {  # and include hyperparameters and metadata\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"epochs\": 1,\n",
    "        \"batch_size\": 64,\n",
    "        \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"CIFAR-10\",\n",
    "        \"train_count\": 2500,\n",
    "        \"test_count\": 200,\n",
    "    }\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "\n",
    "def Model():\n",
    "    inputs = keras.layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "    x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "    x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(len(CLASS_NAMES), activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91b4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = default_config\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train[::5] / 255.0, x_test[::5]  / 255.0\n",
    "y_train, y_test = y_train[::5], y_test[::5]\n",
    "(x_train, y_train) = (x_train[:config['train_count']], y_train[:config['train_count']])\n",
    "(x_test, y_test) = (x_test[:config['test_count']], y_test[:config['test_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aa3c571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 15:18:10.403565: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 50ms/step - loss: 2.2990 - acc: 0.1104 - val_loss: 2.2861 - val_acc: 0.1750\n"
     ]
    }
   ],
   "source": [
    "image_model = Model()\n",
    "optimizer = tf.keras.optimizers.Adam(config['learning_rate'])\n",
    "image_model.compile(optimizer, config['loss_function'], metrics=[\"acc\"])\n",
    "\n",
    "_ = image_model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=config['epochs'],\n",
    "  batch_size=config['batch_size'],\n",
    "  validation_data=(x_test, y_test),\n",
    "#   callbacks=[WandbCallback(\n",
    "#       labels=CLASS_NAMES,\n",
    "#       log_evaluation=True,\n",
    "#   )],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de478f8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "published_image_model = weave.publish(image_model)\n",
    "# published_image_model = weave.save(image_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6468f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frog_small = \"https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog10.png\"\n",
    "ship_small = \"https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship10.png\"\n",
    "truck_small = \"https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck10.png\"\n",
    "plane_small = \"https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane10.png\"\n",
    "\n",
    "frog_url = \"https://www.canr.msu.edu/contentAsset/image/44bc1519-3b22-42b7-9d10-46e3f9f20309/fileAsset/filter/Resize,Jpeg/resize_w/750/jpeg_q/80\"\n",
    "ship_url = \"https://www.itfseafarers.org/sites/default/files/styles/node_main/public/node/issues/image/Cruise%20Ship.jpg?itok=H5WzDqy3\"\n",
    "truck_url = \"https://cdn.motor1.com/images/mgl/G3y6rA/s3/2022-ford-f-series-super-duty.jpg\"\n",
    "plane_url = \"https://media.istockphoto.com/photos/passenger-airplane-flying-above-clouds-during-sunset-picture-id155439315?k=20&m=155439315&s=612x612&w=0&h=BvXCpRLaP5h1NnvyYI_2iRtSM0Xsz2jQhAmZ7nA7abA=\"\n",
    "\n",
    "weave.ops.make_list(\n",
    "    a=weave_keras.image_classification(published_image_model, frog_small),\n",
    "    b=weave_keras.image_classification(published_image_model, ship_small),\n",
    "    c=weave_keras.image_classification(published_image_model, truck_small),\n",
    "    d=weave_keras.image_classification(published_image_model, plane_small),\n",
    "    e=weave_keras.image_classification(published_image_model, frog_url),\n",
    "    f=weave_keras.image_classification(published_image_model, ship_url),\n",
    "    g=weave_keras.image_classification(published_image_model, truck_url),\n",
    "    h=weave_keras.image_classification(published_image_model, plane_url)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3cbb0d",
   "metadata": {},
   "source": [
    "# Train Language Model\n",
    "\n",
    "From: https://keras.io/examples/nlp/text_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec47e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d288f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "# !tar -xf aclImdb_v1.tar.gz\n",
    "# !rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e74e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 15:54:33.852549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Number of batches in raw_train_ds: 625\n",
      "Number of batches in raw_val_ds: 157\n",
      "Number of batches in raw_test_ds: 782\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Having looked at our data above, we see that the raw text contains HTML break\n",
    "# tags of the form '<br />'. These tags will not be removed by the default\n",
    "# standardizer (which doesn't strip HTML). Because of this, we will need to\n",
    "# create a custom standardization function.\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Model constants.\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "\n",
    "# Now that we have our custom standardization, we can instantiate our text\n",
    "# vectorization layer. We are using this layer to normalize, split, and map\n",
    "# strings to integers, so we set our 'output_mode' to 'int'.\n",
    "# Note that we're using the default split function,\n",
    "# and the custom standardization defined above.\n",
    "# We also set an explicit maximum sequence length, since the CNNs later in our\n",
    "# model won't support ragged sequences.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "vectorize_layer_non_custom = TextVectorization(\n",
    "#     standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# Now that the vocab layer has been created, call `adapt` on a text-only\n",
    "# dataset to create the vocabulary. You don't have to batch, but for very large\n",
    "# datasets this means you're not keeping spare copies of the dataset in memory.\n",
    "\n",
    "# Let's make a text-only dataset (no labels):\n",
    "text_ds = raw_train_ds.map(lambda x, y: x)\n",
    "# Let's call `adapt`:\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vectorize_layer_non_custom.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e48486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "\n",
    "# Vectorize the data.\n",
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)\n",
    "\n",
    "# Do async prefetching / buffering of the data for best performance on GPU.\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f053ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# A integer input for vocab indices.\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "text_model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "text_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f177875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 46s 73ms/step - loss: 0.4861 - accuracy: 0.7276 - val_loss: 0.3090 - val_accuracy: 0.8706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1502a8c10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "text_model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a276fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A string input\n",
    "inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n",
    "# Turn strings into vocab indices\n",
    "indices = vectorize_layer_non_custom(inputs)\n",
    "# Turn vocab indices into predictions\n",
    "outputs = text_model(indices)\n",
    "\n",
    "# Our end to end model\n",
    "end_to_end_model = tf.keras.Model(inputs, outputs)\n",
    "end_to_end_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06493feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/local-artifacts/KerasModel/working-X5ZTR0F1BV41/_obj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/local-artifacts/KerasModel/working-X5ZTR0F1BV41/_obj/assets\n"
     ]
    }
   ],
   "source": [
    "saved_text_model = weave.save(end_to_end_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9560ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400px\"\n",
       "            src=\"http://localhost:3000/__frontend/weave_jupyter?fullScreen&expNode=%7B%22nodeType%22%3A%20%22output%22%2C%20%22type%22%3A%20%7B%22type%22%3A%20%22KerasModel%22%2C%20%22inputs_type%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%7B%22type%22%3A%20%22KerasTensor%22%2C%20%22shape%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%22none%22%2C%20%221%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%2C%20%22datatype_enum%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%207%7D%7D%7D%7D%2C%20%22outputs_type%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%7B%22type%22%3A%20%22KerasTensor%22%2C%20%22shape%22%3A%20%7B%22type%22%3A%20%22typedDict%22%2C%20%22propertyTypes%22%3A%20%7B%220%22%3A%20%22none%22%2C%20%221%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%2C%20%22datatype_enum%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22number%22%2C%20%22val%22%3A%201%7D%7D%7D%7D%7D%2C%20%22fromOp%22%3A%20%7B%22name%22%3A%20%22get%22%2C%20%22inputs%22%3A%20%7B%22uri%22%3A%20%7B%22nodeType%22%3A%20%22const%22%2C%20%22type%22%3A%20%7B%22type%22%3A%20%22const%22%2C%20%22valType%22%3A%20%22string%22%2C%20%22val%22%3A%20%22local-artifact%3A///tmp/local-artifacts/KerasModel/6558c37f75b5b9d0a198d4a989ba9f3f%22%7D%2C%20%22val%22%3A%20%22local-artifact%3A///tmp/local-artifacts/KerasModel/6558c37f75b5b9d0a198d4a989ba9f3f%22%7D%7D%7D%7D\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1505cd430>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ddtrace.internal.writer:failed to send traces to Datadog Agent at http://localhost:8126/v0.4/traces\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 407, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 446, in _send_payload\n",
      "    response = self._put(payload, headers)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 398, in _put\n",
      "    self._conn.request(\"PUT\", self._endpoint, data, headers)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1285, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1331, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1280, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 1040, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 980, in send\n",
      "    self.connect()\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\", line 946, in connect\n",
      "    self.sock = self._create_connection(\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\", line 844, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\", line 832, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/ddtrace/internal/writer.py\", line 559, in flush_queue\n",
      "    self._retry_upload(self._send_payload, encoded, n_traces)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 404, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"/Users/timothysweeney/.pyenv/versions/3.9.9/envs/weave_internal/lib/python3.9/site-packages/tenacity/__init__.py\", line 361, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x14ee8f280 state=finished raised ConnectionRefusedError>]\n"
     ]
    }
   ],
   "source": [
    "saved_text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3040ac71",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TypedDict' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mweave_keras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_text_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msingle test string\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/go/src/github.com/wandb/core/services/weave-python/weave-internal/weave/op_def.py:76\u001b[0m, in \u001b[0;36mOpDef.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/go/src/github.com/wandb/core/services/weave-python/weave-internal/weave/lazy.py:159\u001b[0m, in \u001b[0;36mmake_call.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m eager_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/go/src/github.com/wandb/core/services/weave-python/weave-internal/weave/lazy.py:131\u001b[0m, in \u001b[0;36mmake_lazy_call.<locals>.lazy_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    130\u001b[0m     bound_params \u001b[38;5;241m=\u001b[39m _bind_params(fq_op_name, sig, args, kwargs, input_type)\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_make_output_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfq_op_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefine_output_type\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/go/src/github.com/wandb/core/services/weave-python/weave-internal/weave/lazy.py:81\u001b[0m, in \u001b[0;36m_make_output_node\u001b[0;34m(fq_op_name, bound_params, output_type_, refine_output_type)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m callable(output_type):\n\u001b[1;32m     80\u001b[0m     new_input_type \u001b[38;5;241m=\u001b[39m {k: n\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m k, n \u001b[38;5;129;01min\u001b[39;00m bound_params\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 81\u001b[0m     output_type \u001b[38;5;241m=\u001b[39m \u001b[43moutput_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_input_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputNode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m bases \u001b[38;5;241m=\u001b[39m [graph\u001b[38;5;241m.\u001b[39mOutputNode]\n",
      "File \u001b[0;32m~/go/src/github.com/wandb/core/services/weave-python/weave-internal/weave/ecosystem/keras/model.py:214\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(input_types)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(inputs, outputs)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# def call_string_output_type(input_types):\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m#     dimensions = 0\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m#     for input_type in input_types:\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# TODO: Figure out batching - we already have the `None` in the batch index!\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;129m@weave\u001b[39m\u001b[38;5;241m.\u001b[39mop(\n\u001b[1;32m    206\u001b[0m     input_type\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: KerasModel\u001b[38;5;241m.\u001b[39mmake_type([([\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m], DTYPE_NAME\u001b[38;5;241m.\u001b[39mSTRING)]),\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_str\u001b[39m\u001b[38;5;124m\"\u001b[39m: weave\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mString(),\n\u001b[1;32m    209\u001b[0m     },\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# TODO: Get the shapes correct\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     output_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m input_types: List(\n\u001b[1;32m    212\u001b[0m         DTYPE_NAME_TO_WEAVE_TYPE[\n\u001b[1;32m    213\u001b[0m             DTYPE_ENUM_TO_DTYPE_NAME[\n\u001b[0;32m--> 214\u001b[0m                 \u001b[43minput_types\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs_type\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproperty_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m                 \u001b[38;5;241m.\u001b[39mdatatype_enum\u001b[38;5;241m.\u001b[39mval\n\u001b[1;32m    217\u001b[0m             ]\n\u001b[1;32m    218\u001b[0m         ]\n\u001b[1;32m    219\u001b[0m     ),\n\u001b[1;32m    220\u001b[0m )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_string\u001b[39m(model, input_str):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(tf\u001b[38;5;241m.\u001b[39mconstant([input_str]))[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m## The following op (image_classification) is just an example, it needs to be generalized\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# before using it in production.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to do this class lookup as part of the model\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TypedDict' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "weave_keras.call_string(saved_text_model, \"single test string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "weave.panels.Table([\n",
    "    {'input_str': \"This is a test\"},\n",
    "    {'input_str': \"This is a horrible test\"},\n",
    "    {'input_str': \"I love weave\"},\n",
    "    {'input_str': \"please work!\"},\n",
    "    {'input_str': \"I am a person in a house\"},\n",
    "], columns=[\n",
    "    lambda row: row['input_str'],\n",
    "    lambda row: weave_keras.call_string_to_number(saved_text_model, row['input_str'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e435bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# published_text_model = weave.save(end_to_end_model)\n",
    "published_text_model = weave.publish(end_to_end_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weave_keras.call_string_to_number(published_text_model, \"single test string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc3dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
